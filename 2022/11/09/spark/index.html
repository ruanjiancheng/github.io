<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="write something interesting">
    <meta name="author" content="auggie">
    
    <title>
        
            spark |
        
        Auggie&#39;s blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.png">
    
<link rel="stylesheet" href="/fontawesome/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/css/regular.min.css">

    
<link rel="stylesheet" href="/fontawesome/css/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/css/brands.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"zh","path":"search.xml"};
    KEEP.theme_config = {"toc":{"enable":true,"number":false,"expand_all":false,"init_open":false},"style":{"primary_color":"#0066CC","logo":"/images/logo.svg","favicon":"/images/logo.png","avatar":"/images/avatar.png","font_size":null,"font_family":null,"left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"header_transparent":true,"background_img":"/images/bg.svg","description":"Keep running and Keep loving.","font_color":null,"hitokoto":{"enable":false}},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":true}}},"local_search":{"enable":false,"preload":false},"code_copy":{},"code_block_tools":{"enable":true,"style":"default"},"side_tools":{},"pjax":{"enable":false},"lazyload":{"enable":false},"version":"3.4.9"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"};
  </script>
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/logo.svg">
                </a>
            
            <a class="logo-title" href="/">
               Auggie&#39;s blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                ABOUT
                            </a>
                        </li>
                    
                    
                </ul>
            </div>
            <div class="mobile">
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">spark</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/avatar.png">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">auggie</span>
                        
                    </div>
                    <div class="meta-info">
                        
<div class="article-meta-info">
    <span class="article-date article-meta-item">
        
            <i class="fa-regular fa-calendar-plus"></i>&nbsp;
        
        <span class="pc">2022-11-09 09:40:26</span>
        <span class="mobile">2022-11-09 09:40</span>
    </span>
    
        <span class="article-update-date article-meta-item">
        <i class="fas fa-file-pen"></i>&nbsp;
        <span class="pc">2022-12-04 19:26:53</span>
    </span>
    
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/tech/">tech</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>10.6k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>53 Mins</span>
        </span>
    
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <p><a class="link" target="_blank" rel="noopener" href="https://ihainan.gitbooks.io/spark-source-code/content/index.html">apache spark æºç é˜…è¯»<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link" target="_blank" rel="noopener" href="https://dblab.xmu.edu.cn/blog/924/">spark å…¥é—¨æ•™ç¨‹<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link" target="_blank" rel="noopener" href="https://spark.apache.org/">apache spark<i class="fas fa-external-link-alt"></i></a></p>
<h2 id="ç¯å¢ƒå®‰è£…"><a href="#ç¯å¢ƒå®‰è£…" class="headerlink" title="ç¯å¢ƒå®‰è£…"></a>ç¯å¢ƒå®‰è£…</h2><h3 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h3><blockquote>
<p>sshå…å¯†ç ç™»é™†</p>
</blockquote>
<ol>
<li>åœ¨macçš„<strong>ç³»ç»Ÿåå¥½è®¾ç½®â€“&gt;å…±äº«</strong>ä¸­æ‰“å¼€è¿œç¨‹ç™»å½•</li>
<li><code>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</code></li>
<li><code>ssh localhost</code></li>
</ol>
<blockquote>
<p>hadoop</p>
</blockquote>
<p><a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/pgs1004151212/article/details/104391391">hadoop mac é…ç½®<i class="fas fa-external-link-alt"></i></a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install hadoop</span><br></pre></td></tr></table></figure>

<p>Hadoop ä¼ªåˆ†å¸ƒå¼é…ç½®ï¼š</p>
<ol>
<li><code>/opt/homebrew/Cellar/hadoop/3.3.4/libexec/etc/hadoop/core-site.xml</code> é…ç½®å¦‚ä¸‹ä¿¡æ¯ï¼š</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/opt/homebrew/Cellar/hadoop/3.3.4/libexec/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li><code>/opt/homebrew/Cellar/hadoop/3.3.4/libexec/etc/hadoop/hdfs-site.xml</code> é…ç½®ä¿¡æ¯å¦‚ä¸‹ï¼š</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/opt/homebrew/Cellar/hadoop/3.3.4/libexec/tmp/dfs/nam    e<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/opt/homebrew/Cellar/hadoop/3.3.4/libexec/tmp/dfs/dat    a<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<ol start="3">
<li>Env é…ç½®</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export CLASSPAHT=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">149 export HADOOP_HOME=/opt/homebrew/Cellar/hadoop/3.3.4/libexec</span><br><span class="line">150 export HADOOP_COMMON_HOME=$HADOOP_HOME</span><br><span class="line">151 export PATH=$JAVA_HOME/bin:$PATH:$HADOOP_HOME/bin:/opt//homebrew/Cellar/scala/bin</span><br></pre></td></tr></table></figure>



<blockquote>
<p>è¿è¡Œ hadoop ç¨‹åº</p>
</blockquote>
<ol>
<li><p>åˆå§‹åŒ–ï¼šhdfs namenode -format </p>
</li>
<li><p><code>start-dfs.sh</code></p>
<p><a class="link" target="_blank" rel="noopener" href="https://stackoverflow.com/questions/44009058/even-though-jre-8-is-installed-on-my-mac-no-java-runtime-present-requesting-t">æ‰¾ä¸åˆ° JRE<i class="fas fa-external-link-alt"></i></a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(base) âœ  ~ start-dfs.sh</span><br><span class="line">Starting namenodes on [localhost]</span><br><span class="line">localhost: WARNING: /opt/homebrew/Cellar/hadoop/3.3.4/libexec/logs does not exist. Creating.</span><br><span class="line">Starting datanodes</span><br><span class="line">Starting secondary namenodes [Y3Y54Q72DR]</span><br><span class="line">Y3Y54Q72DR: ssh: Could not resolve hostname y3y54q72dr: nodename nor servname provided, or not known</span><br><span class="line">2022-11-09 16:17:23,985 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br></pre></td></tr></table></figure>
</li>
<li><p>æŸ¥çœ‹æ˜¯å¦å¯åŠ¨ <code>jps</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(base) âœ  ~ jps</span><br><span class="line">86881</span><br><span class="line">56226 Jps</span><br><span class="line">22195</span><br><span class="line">55683 NameNode</span><br><span class="line">39907 NailgunRunner</span><br><span class="line">55786 DataNode</span><br><span class="line">43003 Launcher</span><br><span class="line">23211 Application</span><br><span class="line">30365</span><br></pre></td></tr></table></figure>
</li>
<li><p>æŸ¥çœ‹ namenodeï¼Œ <a class="link" target="_blank" rel="noopener" href="http://localhost:9870/dfshealth.html#tab-overview">http://localhost:9870/dfshealth.html#tab-overview<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p>ä¿®æ”¹ <code>yarn</code> é…ç½®æ–‡ä»¶ã€‚<code>/opt/homebrew/Cellar/hadoop/3.3.4/libexec/etc/hadoop/mapred-site.xml</code> æ·»åŠ å†…å®¹ï¼š</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name</span><br><span class="line">        <span class="tag">&lt;/<span class="name">name</span>&gt;</span>	</span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ä¿®æ”¹ <code>/opt/homebrew/Cellar/hadoop/3.3.4/libexec/etc/hadoop/yarn-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>å¯åŠ¨ <code>yarn</code>ï¼Œ<code>start-yarn.sh</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(base) âœ  hadoop git:(stable) start-yarn.sh</span><br><span class="line">Starting resourcemanager</span><br><span class="line">Starting nodemanagers</span><br></pre></td></tr></table></figure>

<p>æµè§ˆå™¨ä¸­æ‰“å¼€ï¼š<a class="link" target="_blank" rel="noopener" href="http://localhost:8088/cluster">http://localhost:8088/cluster<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p>è¿è¡Œ Hadoop è‡ªå¸¦çš„ wordcount ç¨‹åº</p>
<ul>
<li><code>hadoop fs -mkdir /input</code> åˆ›å»ºæ–‡ä»¶å¤¹</li>
<li><code>hadoop fs -ls /</code> æŸ¥çœ‹æ–‡ä»¶å¤¹</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">(base) âœ  hadoop git:(stable) hadoop fs -mkdir /input</span><br><span class="line">2022-11-09 16:27:09,642 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">(base) âœ  hadoop git:(stable) hadoop fs -ls /</span><br><span class="line">2022-11-09 16:27:30,749 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - bytedance supergroup          0 2022-11-09 16:27 /input</span><br></pre></td></tr></table></figure>
</li>
<li><p>è¿è¡Œç¨‹åº <code>hadoop jar /opt/homebrew/Cellar/hadoop/3.3.4/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar   wordcount /input /output</code></p>
</li>
</ol>
<h3 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h3><p>å¤ªéº»çƒ¦äº†ï¼ˆ</p>
<p><a class="link" target="_blank" rel="noopener" href="https://www.yiibai.com/hive/hive_installation.html">Hive install<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link" target="_blank" rel="noopener" href="https://www.jianshu.com/p/3fef90437a9c">Hive install<i class="fas fa-external-link-alt"></i></a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_HOME=/usr/local/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br><span class="line">export CLASSPATH=$CLASSPATH:/usr/local/Hadoop/lib/*:.</span><br><span class="line">export CLASSPATH=$CLASSPATH:/usr/local/hive/lib/*:.</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_HOME=/opt/homebrew/Cellar/hadoop/3.3.4/libexec</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Hive Configuration Directory can be controlled by:</span></span><br><span class="line">export HIVE_CONF_DIR=/usr/local/hive/conf</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Folder containing extra libraries required <span class="keyword">for</span> hive compilation/    execution can be controlled by:</span></span><br><span class="line">export HIVE_AUX_JARS_PATH=/usr/local/hive/lib</span><br></pre></td></tr></table></figure>



<p><code>hive-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratchdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:8020/data/hive/temp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:8020/data/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:8020/data/hive/log<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    &lt;!â€”è¯¥é…ç½®æ˜¯å…³é—­hiveå…ƒæ•°æ®ç‰ˆæœ¬è®¤è¯ï¼Œå¦åˆ™ä¼šåœ¨å¯åŠ¨sparkç¨‹åºæ—¶æŠ¥é”™--&gt;</span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>





<h3 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h3><p><a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/vbirdbest/article/details/104499826">csdn spark<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link" target="_blank" rel="noopener" href="https://dblab.xmu.edu.cn/blog/1307/">xmu spark<i class="fas fa-external-link-alt"></i></a></p>
<ol>
<li><p>å®‰è£… <code>scala</code>ï¼Œå¿…é¡»å®‰è£… spark æŒ‡å®šçš„ç‰ˆæœ¬ï¼Œä¸ç„¶ spark ä¼šæŠ¥é”™</p>
</li>
<li><p>ä¸‹è½½ <code>spark</code>ï¼Œ<a class="link" target="_blank" rel="noopener" href="https://spark.apache.org/downloads.html">sparkå®˜ç½‘<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p>å®‰è£… é…ç½® <code>spark</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxf ~/ä¸‹è½½/spark-2.1.0-bin-without-hadoop.tgz -C /usr/local/cd /usr/local</span><br><span class="line">sudo <span class="built_in">mv</span> ./spark-2.1.0-bin-without-hadoop/ ./spark</span><br><span class="line">sudo <span class="built_in">chown</span> -R hadoop:hadoop ./spark          <span class="comment"># æ­¤å¤„çš„ hadoop ä¸ºä½ çš„ç”¨æˆ·å</span></span><br></pre></td></tr></table></figure>

<p>å®‰è£…åï¼Œè¿˜éœ€è¦ä¿®æ”¹Sparkçš„é…ç½®æ–‡ä»¶spark-env.sh</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$SPARK_HOME</span></span><br><span class="line"><span class="built_in">cp</span> ./conf/spark-env.sh.template ./conf/spark-env.sh</span><br></pre></td></tr></table></figure>

<p>ç¼–è¾‘spark-env.shæ–‡ä»¶(vim .&#x2F;conf&#x2F;spark-env.sh)ï¼Œåœ¨ç¬¬ä¸€è¡Œæ·»åŠ ä»¥ä¸‹é…ç½®ä¿¡æ¯:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export SPARK_DIST_CLASSPATH=$(/opt/homebrew/bin/hadoop classpath)</span><br></pre></td></tr></table></figure>

<p>æœ‰äº†ä¸Šé¢çš„é…ç½®ä¿¡æ¯ä»¥åï¼ŒSparkå°±å¯ä»¥æŠŠæ•°æ®å­˜å‚¨åˆ°Hadoopåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»ŸHDFSä¸­ï¼Œä¹Ÿå¯ä»¥ä»HDFSä¸­è¯»å–æ•°æ®ã€‚å¦‚æœæ²¡æœ‰é…ç½®ä¸Šé¢ä¿¡æ¯ï¼ŒSparkå°±åªèƒ½è¯»å†™æœ¬åœ°æ•°æ®ï¼Œæ— æ³•è¯»å†™HDFSæ•°æ®ã€‚</p>
</li>
<li><p>éªŒè¯å®‰è£…</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/run-example SparkPi 2&gt;&amp;1 | grep &quot;Pi is&quot;</span><br><span class="line"></span><br><span class="line">(base) âœ  spark-3.3.1-bin-hadoop3 git:(stable) bin/run-example SparkPi 2&gt;&amp;1 | grep &quot;Pi is&quot;</span><br><span class="line">Pi is roughly 3.1459757298786495</span><br></pre></td></tr></table></figure>
</li>
<li><p>å¯åŠ¨ spark</p>
<p><a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43042683/article/details/105397046">localhost: namenode running as process 2896. Stop it first.<i class="fas fa-external-link-alt"></i></a></p>
<p>ä¸è¦å¯åŠ¨åˆ° <code>hadoop</code> çš„ <code>start_all.sh</code> äº†ğŸ˜‡</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">(base) âœ  ~ cd $SPARK_HOME/sbin</span><br><span class="line">(base) âœ  sbin git:(stable) ./start-all.sh</span><br><span class="line">starting org.apache.spark.deploy.master.Master, logging to /opt/homebrew/Cellar/spark-3.3.1-bin-hadoop3/logs/spark-bytedance-org.apache.spark.deploy.master.Master-1-Y3Y54Q72DR.out</span><br><span class="line">localhost: starting org.apache.spark.deploy.worker.Worker, logging to /opt/homebrew/Cellar/spark-3.3.1-bin-hadoop3/logs/spark-bytedance-org.apache.spark.deploy.worker.Worker-1-Y3Y54Q72DR.out</span><br><span class="line">(base) âœ  sbin git:(stable) jps</span><br><span class="line">86881</span><br><span class="line">67523 Master</span><br><span class="line">22195</span><br><span class="line">67634 Worker</span><br><span class="line">67669 Jps</span><br><span class="line">66823 NameNode</span><br><span class="line">43003 Launcher</span><br><span class="line">23211 Application</span><br><span class="line">67197 ResourceManager</span><br><span class="line">30365</span><br><span class="line">66927 DataNode</span><br></pre></td></tr></table></figure>

<p><a class="link" target="_blank" rel="noopener" href="http://localhost:8080/">spark æœ¬åœ°åœ°å€<i class="fas fa-external-link-alt"></i></a></p>
</li>
<li><p>å¯åŠ¨ <code>spark shell</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">spark-shell --master &lt;master-url&gt;</span><br><span class="line"></span><br><span class="line">* local ä½¿ç”¨ä¸€ä¸ªWorkerçº¿ç¨‹æœ¬åœ°åŒ–è¿è¡ŒSPARK(å®Œå…¨ä¸å¹¶è¡Œ)</span><br><span class="line">* local[*] ä½¿ç”¨é€»è¾‘CPUä¸ªæ•°æ•°é‡çš„çº¿ç¨‹æ¥æœ¬åœ°åŒ–è¿è¡ŒSpark</span><br><span class="line">* local[K] ä½¿ç”¨Kä¸ªWorkerçº¿ç¨‹æœ¬åœ°åŒ–è¿è¡ŒSparkï¼ˆç†æƒ³æƒ…å†µä¸‹ï¼ŒKåº”è¯¥æ ¹æ®è¿è¡Œæœºå™¨çš„CPUæ ¸æ•°è®¾å®šï¼‰</span><br><span class="line">* spark://HOST:PORT è¿æ¥åˆ°æŒ‡å®šçš„Spark standalone masterã€‚é»˜è®¤ç«¯å£æ˜¯7077.</span><br><span class="line">* yarn-client ä»¥å®¢æˆ·ç«¯æ¨¡å¼è¿æ¥YARNé›†ç¾¤ã€‚é›†ç¾¤çš„ä½ç½®å¯ä»¥åœ¨HADOOP_CONF_DIR ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ°ã€‚</span><br><span class="line">* yarn-cluster ä»¥é›†ç¾¤æ¨¡å¼è¿æ¥YARNé›†ç¾¤ã€‚é›†ç¾¤çš„ä½ç½®å¯ä»¥åœ¨HADOOP_CONF_DIR ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ°ã€‚</span><br><span class="line">* mesos://HOST:PORT è¿æ¥åˆ°æŒ‡å®šçš„Mesosé›†ç¾¤ã€‚é»˜è®¤æ¥å£æ˜¯5050ã€‚</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd $SPARK_HOME/bin</span><br><span class="line">./spark-shell --master local</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Welcome to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  &#x27;_/</span><br><span class="line">   /___/ .__/\_,_/_/ /_/\_\   version 3.3.1</span><br><span class="line">      /_/</span><br><span class="line"></span><br><span class="line">Using Scala version 2.12.15 (OpenJDK 64-Bit Server VM, Java 1.8.0_292)</span><br><span class="line">Type in expressions to have them evaluated.</span><br><span class="line">Type :help for more information.</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">scala&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="Spark-ç‹¬ç«‹åº”ç”¨ç¨‹åºç¼–ç¨‹"><a href="#Spark-ç‹¬ç«‹åº”ç”¨ç¨‹åºç¼–ç¨‹" class="headerlink" title="Spark ç‹¬ç«‹åº”ç”¨ç¨‹åºç¼–ç¨‹"></a>Spark ç‹¬ç«‹åº”ç”¨ç¨‹åºç¼–ç¨‹</h3><h4 id="é‡åˆ°çš„å‘"><a href="#é‡åˆ°çš„å‘" class="headerlink" title="é‡åˆ°çš„å‘"></a>é‡åˆ°çš„å‘</h4><ul>
<li><p>è·¯å¾„é—®é¢˜ï¼š</p>
<p>spark åº”è¯¥ä¼šä» hdfs ä¸Šé¢æŸ¥æ‰¾æ–‡ä»¶ã€‚å¦‚æœéœ€è¦æŸ¥æ‰¾æœ¬åœ°æ–‡ä»¶çš„è¯ï¼Œéœ€è¦ä½¿ç”¨ <code>file:</code> å¼€å¤´ï¼Œä¾‹å¦‚ï¼š</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> logFile = <span class="string">&quot;file:/Users/bytedance/resource/fyy/log.log&quot;</span></span><br></pre></td></tr></table></figure>


</li>
<li><p>æ‰¾ä¸åˆ° class çš„é—®é¢˜ï¼š</p>
<ul>
<li><p>é¦–å…ˆåŒ…å« <code>main</code> æ–¹æ³•çš„ç±»åè¦å’Œ <code>--class</code> è¾“å…¥çš„ç±»åä¿æŒä¸€è‡´ã€‚</p>
</li>
<li><p>ä½¿ç”¨ idea ä¼šæŠ¥é”™ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆã€‚ä¹‹åè¿˜æ˜¯ç”¨ vscode å§ğŸ˜‡</p>
<p>å¦‚ä¸‹ï¼š</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">Error: Failed to load class SimpleApp.</span><br><span class="line">22/11/10 11:22:42 INFO ShutdownHookManager: Shutdown hook called</span><br><span class="line">22/11/10 11:22:42 INFO ShutdownHookManager: Deleting directory /private/var/folders/b1/0fd1b6hs7lz0fm_mh346lybm0000gn/T/spark-533682ae-17f9-4229-a3d0-a621fe441511</span><br></pre></td></tr></table></figure></li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SimpleApp</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> logFile = <span class="string">&quot;file:/Users/bytedance/resource/fyy/log.log&quot;</span> <span class="comment">// Should be some file on your system</span></span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder.appName(<span class="string">&quot;Simple Application&quot;</span>).getOrCreate()</span><br><span class="line">    <span class="keyword">val</span> logData = spark.read.textFile(logFile).cache()</span><br><span class="line">    <span class="keyword">val</span> numAs = logData.filter(line =&gt; line.contains(<span class="string">&quot;a&quot;</span>)).count()</span><br><span class="line">    <span class="keyword">val</span> numBs = logData.filter(line =&gt; line.contains(<span class="string">&quot;b&quot;</span>)).count()</span><br><span class="line">    println(<span class="string">s&quot;Lines with a: <span class="subst">$numAs</span>, Lines with b: <span class="subst">$numBs</span>&quot;</span>)</span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">name := <span class="string">&quot;Simple App&quot;</span></span><br><span class="line"></span><br><span class="line">version := <span class="string">&quot;1.0&quot;</span></span><br><span class="line"></span><br><span class="line">scalaVersion := <span class="string">&quot;2.13.10&quot;</span></span><br><span class="line"></span><br><span class="line">libraryDependencies += <span class="string">&quot;org.apache.spark&quot;</span> %% <span class="string">&quot;spark-sql&quot;</span> % <span class="string">&quot;3.3.1&quot;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="ä¸¤ç§-sparkcontext-å§¿åŠ¿"><a href="#ä¸¤ç§-sparkcontext-å§¿åŠ¿" class="headerlink" title="ä¸¤ç§ sparkcontext å§¿åŠ¿"></a>ä¸¤ç§ sparkcontext å§¿åŠ¿</h4><p><a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35235032/article/details/109222246">sparkcontext é…ç½® hdfs<i class="fas fa-external-link-alt"></i></a></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkContext</span>._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SimpleApp</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;SimpleApp&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="keyword">val</span> filename = <span class="string">&quot;hdfs://localhost:8020/user/spark/word.txt&quot;</span></span><br><span class="line">    <span class="keyword">val</span> txt = sc.textFile(filename)</span><br><span class="line">    <span class="keyword">val</span> res = txt.flatMap(line =&gt; line.split(<span class="string">&quot; &quot;</span>)).filter(_.size &gt; <span class="number">0</span>).map(word =&gt; (word -&gt; <span class="number">1</span>))</span><br><span class="line">    .reduceByKey(_ + _).collect()</span><br><span class="line">    res.foreach(println)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SimpleApp</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder().config(<span class="string">&quot;spark.master&quot;</span>, <span class="string">&quot;local&quot;</span>).getOrCreate()</span><br><span class="line">    <span class="keyword">val</span> sc = spark.sparkContext</span><br><span class="line">    <span class="keyword">val</span> filename = <span class="string">&quot;hdfs://localhost:8020/user/spark/word.txt&quot;</span></span><br><span class="line">    <span class="keyword">val</span> txt = sc.textFile(filename)</span><br><span class="line">    <span class="keyword">val</span> res = txt.flatMap(line =&gt; line.split(<span class="string">&quot; &quot;</span>)).filter(_.size &gt; <span class="number">0</span>).map(word =&gt; (word -&gt; <span class="number">1</span>))</span><br><span class="line">    .reduceByKey(_ + _).collect()</span><br><span class="line">    res.foreach(println)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<p>è¾“å‡ºï¼š</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(base) âœ  sparkapp $SPARK_HOME/bin/spark-submit \</span><br><span class="line">--class &quot;SimpleApp&quot; \</span><br><span class="line">--master local \</span><br><span class="line">./target/scala-2.13/simple-app_2.13-1.0.jar 2&amp;&gt;1 | grep &quot;Line&quot;</span><br><span class="line">Lines with a: 16, Lines with b: 15</span><br></pre></td></tr></table></figure>

<h4 id="wordCount"><a href="#wordCount" class="headerlink" title="wordCount"></a>wordCount</h4><blockquote>
<p>ä¸€äº›å¸¸ç”¨çš„å‡½æ•°</p>
</blockquote>
<p>æ–‡ä»¶è¯»å†™ï¼š</p>
<ul>
<li>è¯»å†™æœ¬åœ°æ–‡ä»¶</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// è¯»å–æ–‡ä»¶	å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶ å¿…é¡»ç”¨ file:// å¼€å¤´ï¼Œç”¨äºåŒºåˆ† hdfs</span></span><br><span class="line"><span class="keyword">val</span> file = sc.textFile(filepath)</span><br><span class="line"></span><br><span class="line"><span class="comment">// spark æ‡’åŠ è½½ï¼ŒåŠ è½½æ–‡ä»¶çš„ç¬¬ä¸€è¡Œ</span></span><br><span class="line">file.first()</span><br><span class="line"></span><br><span class="line"><span class="comment">// textFile å†™ä¼š</span></span><br><span class="line">file.saveasTextFile(filepath)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ul>
<li>è¯»å†™ hdfs æ–‡ä»¶</li>
</ul>
<p>hdfs å¸¸ç”¨å‘½ä»¤ï¼š</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir hdfspath</span><br><span class="line"></span><br><span class="line">hdfs dfs -ls hdfspath</span><br><span class="line"></span><br><span class="line">hdfs dfs -put localpath hfdspath</span><br><span class="line"></span><br><span class="line">hdfs dfs -cat hdfsfile</span><br><span class="line"></span><br><span class="line">hdfs dfs -get</span><br><span class="line"></span><br><span class="line">hdfs getconf -confKey fs.default.name # è·å–æœ¬åœ° hdfs ç«¯å£å·</span><br></pre></td></tr></table></figure>

<p>spark è¯»å– hdfs è·¯å¾„ï¼š</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> textFile = sc.textFile(<span class="string">&quot;hdfs://localhost:8020/user/spark/word.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// å®é™…ä¸Šå¯ä»¥çœç•¥ä¸å†™</span></span><br><span class="line"><span class="keyword">val</span> textFile = sc.textFile(<span class="string">&quot;/user/spark/word.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// è¯»å†™æ“ä½œå’Œæœ¬åœ°æ–‡ä»¶ç±»ä¼¼</span></span><br></pre></td></tr></table></figure>



<p>è¯é¢‘ç»Ÿè®¡ï¼š</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">textFile.flatMap(line =&gt; line.split(<span class="string">&quot; &quot;</span>)).map(word =&gt; (word, <span class="number">1</span>)).reduceByKey((a, b) =&gt; a + b).foreach(println)</span><br></pre></td></tr></table></figure>



<h3 id="é…ç½®-vscode-scala-spark-ç¯å¢ƒ"><a href="#é…ç½®-vscode-scala-spark-ç¯å¢ƒ" class="headerlink" title="é…ç½® vscode scala spark ç¯å¢ƒ"></a>é…ç½® vscode scala spark ç¯å¢ƒ</h3><p><a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/lyd882/article/details/111638953">vscode scala<i class="fas fa-external-link-alt"></i></a></p>
<h4 id="vscode-é…ç½®-scalafmt-å¯„äº†ï¼Œå»ºè®®ç”¨-idea"><a href="#vscode-é…ç½®-scalafmt-å¯„äº†ï¼Œå»ºè®®ç”¨-idea" class="headerlink" title="vscode é…ç½® scalafmt (å¯„äº†ï¼Œå»ºè®®ç”¨ idea)"></a>vscode é…ç½® scalafmt (å¯„äº†ï¼Œå»ºè®®ç”¨ idea)</h4><p><a class="link" target="_blank" rel="noopener" href="https://scalameta.org/scalafmt/docs/installation.html#metals">vscode scalafmt<i class="fas fa-external-link-alt"></i></a></p>
<p>åœ¨ <code>project</code> ä¸­æ·»åŠ  <code>plugins.sbt</code> æ–‡ä»¶</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// In project/plugins.sbt. Note, does not support sbt 0.13, only sbt 1.x.</span></span><br><span class="line">addSbtPlugin(<span class="string">&quot;org.scalameta&quot;</span> % <span class="string">&quot;sbt-scalafmt&quot;</span> % <span class="type">SBT_PLUGIN_VERSION</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// idea</span></span><br><span class="line">addSbtPlugin(<span class="string">&quot;org.jetbrains.scala&quot;</span> % <span class="string">&quot;sbt-ide-settings&quot;</span> % <span class="string">&quot;1.1.1&quot;</span>)</span><br></pre></td></tr></table></figure>



<p>æ·»åŠ  <code>.scalafmt.config</code> æ–‡ä»¶</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">version = <span class="number">2.7</span><span class="number">.5</span></span><br></pre></td></tr></table></figure>



<h2 id="Spark-è¿è¡Œæµç¨‹"><a href="#Spark-è¿è¡Œæµç¨‹" class="headerlink" title="Spark è¿è¡Œæµç¨‹"></a>Spark è¿è¡Œæµç¨‹</h2><p><a class="link" target="_blank" rel="noopener" href="https://www.cnblogs.com/frankdeng/p/9301485.html">spark è¿è¡Œæµç¨‹<i class="fas fa-external-link-alt"></i></a></p>
<p><img src="https://images2018.cnblogs.com/blog/1228818/201804/1228818-20180425170820868-121220770.png" alt="spark-process"></p>
<ol>
<li>Spark åº”ç”¨ç¨‹åºè¢«æäº¤ï¼Œä»»åŠ¡æ§åˆ¶èŠ‚ç‚¹(Driver)åˆ›å»ºä¸€ä¸ª SparkContextã€‚SparkContextä¼šå‘èµ„æºç®¡ç†å™¨(Cluster Manager)æ³¨å†Œå¹¶ç”³è¯·è¿è¡ŒExecutorçš„èµ„æºã€‚</li>
<li>Cluster Manager ä¸º Executor åˆ†é…èµ„æºï¼Œå¯åŠ¨ executor è¿›ç¨‹ï¼Œexecutorè¿è¡Œæƒ…å†µå°†éšç€â€œå¿ƒè·³â€å‘é€åˆ°èµ„æºç®¡ç†å™¨ä¸Šã€‚</li>
<li>RDD -&gt; DAG -&gt; task set(stage) -&gt; executor</li>
<li>ä»»åŠ¡åœ¨Executorä¸Šè¿è¡Œï¼ŒæŠŠæ‰§è¡Œç»“æœåé¦ˆç»™ä»»åŠ¡è°ƒåº¦å™¨ï¼Œç„¶ååé¦ˆç»™DAGè°ƒåº¦å™¨ï¼Œè¿è¡Œå®Œæ¯•åå†™å…¥æ•°æ®å¹¶é‡Šæ”¾æ‰€æœ‰èµ„æºã€‚</li>
</ol>
<p>ä¸€ä¸ªä»»åŠ¡åˆ›å»ºåœ¨ä¸€ä¸ª worker ä¸Šé¢åˆ›å»ºä¸€ä¸ª exector</p>
<h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>ä¸€ä¸ªRDDå°±æ˜¯ä¸€ä¸ª<strong>åˆ†å¸ƒå¼å¯¹è±¡é›†åˆ</strong>ï¼Œæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ª<strong>åªè¯»</strong>çš„åˆ†åŒºè®°å½•é›†åˆï¼Œæ¯ä¸ªRDDå¯ä»¥åˆ†æˆå¤šä¸ªåˆ†åŒºï¼Œæ¯ä¸ªåˆ†åŒºå°±æ˜¯ä¸€ä¸ªæ•°æ®é›†ç‰‡æ®µï¼Œå¹¶ä¸”ä¸€ä¸ªRDDçš„<strong>ä¸åŒåˆ†åŒºå¯ä»¥è¢«ä¿å­˜åˆ°é›†ç¾¤ä¸­ä¸åŒçš„èŠ‚ç‚¹ä¸Šï¼Œä»è€Œå¯ä»¥åœ¨é›†ç¾¤ä¸­çš„ä¸åŒèŠ‚ç‚¹ä¸Šè¿›è¡Œå¹¶è¡Œè®¡ç®—ã€‚</strong></p>
<ul>
<li><p>å®¹é”™ï¼šé€šè¿‡ RDD çš„ DAG å®ç°å®¹é”™</p>
</li>
<li><p>ä¸­é—´ç»“æœæŒä¹…åŒ–åˆ°å†…å­˜</p>
</li>
<li><p>å­˜æ”¾æ•°æ®å¯ä»¥æ˜¯ Java obj</p>
</li>
<li><p>Narrowï¼šä¸€å¯¹ä¸€ï¼Œå¤šå¯¹ä¸€</p>
</li>
<li><p>Wildï¼šä¸€å¯¹å¤š</p>
</li>
</ul>
<p><img src="https://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-10-%E7%AA%84%E4%BE%9D%E8%B5%96%E4%B8%8E%E5%AE%BD%E4%BE%9D%E8%B5%96%E7%9A%84%E5%8C%BA%E5%88%AB.jpg" alt="narrow &amp; wild"></p>
<blockquote>
<p>é˜¶æ®µåˆ’åˆ†</p>
</blockquote>
<p>åœ¨DAGä¸­è¿›è¡Œåå‘è§£æï¼Œ<strong>é‡åˆ°å®½ä¾èµ–å°±æ–­å¼€</strong>ï¼Œ<strong>é‡åˆ°çª„ä¾èµ–å°±æŠŠå½“å‰çš„RDDåŠ å…¥åˆ°å½“å‰çš„é˜¶æ®µä¸­</strong>ï¼›å°†çª„ä¾èµ–å°½é‡åˆ’åˆ†åœ¨åŒä¸€ä¸ªé˜¶æ®µä¸­ï¼Œå¯ä»¥å®ç°æµæ°´çº¿è®¡ç®—ã€‚</p>
<p><img src="https://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-11-%E6%A0%B9%E6%8D%AERDD%E5%88%86%E5%8C%BA%E7%9A%84%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E5%88%92%E5%88%86%E9%98%B6%E6%AE%B5.jpg" alt="åˆ’åˆ†"></p>
<blockquote>
<p>è¿è¡Œè¿‡ç¨‹</p>
</blockquote>
<ul>
<li>åˆ›å»º RDDï¼ŒsparkContext è§£æä¾èµ–å…³ç³»ï¼Œç”Ÿæˆ DAG</li>
<li>DAGScheduler å°† DAG æ‹†æˆå¤šä¸ª stageã€‚</li>
<li>æ¯ä¸ªé˜¶æ®µä¸­åŒ…å«äº†å¤šä¸ªä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡ä¼šè¢«ä»»åŠ¡è°ƒåº¦å™¨åˆ†å‘ç»™å„ä¸ªå·¥ä½œèŠ‚ç‚¹ï¼ˆWorker Nodeï¼‰ä¸Šçš„Executorå»æ‰§è¡Œã€‚</li>
</ul>
<p><img src="https://dblab.xmu.edu.cn/blog/wp-content/uploads/2016/11/%E5%9B%BE9-12-RDD%E5%9C%A8Spark%E4%B8%AD%E7%9A%84%E8%BF%90%E8%A1%8C%E8%BF%87%E7%A8%8B.jpg" alt="process"></p>
<h3 id="RDDåˆ›å»º"><a href="#RDDåˆ›å»º" class="headerlink" title="RDDåˆ›å»º"></a>RDDåˆ›å»º</h3><ul>
<li><p>è¯»å–å¤–éƒ¨æ•°æ®é›†ï¼ŒHDFSï¼ŒLOCALï¼ŒKafka</p>
<p>å¦‚æœä½¿ç”¨äº†æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿçš„è·¯å¾„ï¼Œé‚£ä¹ˆï¼Œ<strong>å¿…é¡»è¦ä¿è¯åœ¨æ‰€æœ‰çš„workerèŠ‚ç‚¹ä¸Šï¼Œä¹Ÿéƒ½èƒ½å¤Ÿé‡‡ç”¨ç›¸åŒçš„è·¯å¾„è®¿é—®åˆ°è¯¥æ–‡ä»¶ï¼Œ</strong>æ¯”å¦‚ï¼Œå¯ä»¥æŠŠè¯¥æ–‡ä»¶æ‹·è´åˆ°æ¯ä¸ªworkerèŠ‚ç‚¹ä¸Šï¼Œæˆ–è€…ä¹Ÿå¯ä»¥ä½¿ç”¨ç½‘ç»œæŒ‚è½½å…±äº«æ–‡ä»¶ç³»ç»Ÿã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> lines = sc.textFile(<span class="string">&quot;file:///usr/local/spark/mycode/rdd/word.txt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> lines = sc.textFile(<span class="string">&quot;hdfs://localhost:9000/user/hadoop/word.txt&quot;</span>)</span><br></pre></td></tr></table></figure>


</li>
<li><p>è°ƒç”¨ SparkContext çš„ parallelize æ–¹æ³•ï¼Œåœ¨å·²æœ‰çš„é›†åˆä¸Šé¢åˆ›å»ºä¸€ä¸ª RDD</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> list = (<span class="number">1</span> to <span class="number">10</span>).toList</span><br><span class="line"><span class="keyword">val</span> array = (<span class="number">1</span> to <span class="number">10</span>).toArray</span><br><span class="line"><span class="keyword">val</span> rdd = sc.parallelize(list)</span><br><span class="line"><span class="keyword">val</span> rdd = sc.parallelize(array)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="RDDæ“ä½œ"><a href="#RDDæ“ä½œ" class="headerlink" title="RDDæ“ä½œ"></a>RDDæ“ä½œ</h3><p>RDD åˆ›å»ºä¹‹åï¼Œåœ¨åç»­è¿‡ç¨‹ä¸­ä¸€èˆ¬åªä¼šå‘ç”Ÿä¸¤ç§æ“ä½œï¼š</p>
<ul>
<li>transformationï¼šRDD &#x3D;&gt; newRDD</li>
<li>Action: åœ¨æ•°æ®é›†ä¸Šè¿ç®—ï¼Œè¿”å›ç»“æœ</li>
</ul>
<h4 id="transformation"><a href="#transformation" class="headerlink" title="transformation"></a>transformation</h4><ul>
<li>filter(func)</li>
<li>map(func)</li>
<li>flatMap(func)</li>
<li>groupByKey()</li>
<li>reduceByKey(func)</li>
</ul>
<h4 id="action"><a href="#action" class="headerlink" title="action"></a>action</h4><ul>
<li>count() </li>
<li>collect() ä»¥æ•°ç»„çš„å½¢å¼è¿”å›æ•°æ®é›†ä¸­çš„æ‰€æœ‰å…ƒç´ </li>
<li>first() </li>
<li>take(n)</li>
<li>reduce(func)</li>
<li>foreach(func)</li>
</ul>
<h3 id="RDDæŒä¹…åŒ–"><a href="#RDDæŒä¹…åŒ–" class="headerlink" title="RDDæŒä¹…åŒ–"></a>RDDæŒä¹…åŒ–</h3><p>RDDé‡‡ç”¨æƒ°æ€§æ±‚å€¼çš„æœºåˆ¶ï¼Œæ¯æ¬¡é‡åˆ°è¡ŒåŠ¨æ“ä½œï¼Œ<strong>éƒ½ä¼šä»å¤´å¼€å§‹æ‰§è¡Œè®¡ç®—</strong>ã€‚</p>
<p>åœ¨ä¸€äº›æƒ…å½¢ä¸‹ï¼Œæˆ‘ä»¬éœ€è¦å¤šæ¬¡è°ƒç”¨ä¸åŒçš„è¡ŒåŠ¨æ“ä½œï¼Œè¿™å°±æ„å‘³ç€ï¼Œæ¯æ¬¡è°ƒç”¨è¡ŒåŠ¨æ“ä½œï¼Œéƒ½ä¼šè§¦å‘ä¸€æ¬¡ä»å¤´å¼€å§‹çš„è®¡ç®—ã€‚</p>
<p>é€šè¿‡æŒä¹…åŒ–æœºåˆ¶é¿å…è¿™ç§é‡å¤è®¡ç®—çš„å¼€é”€ã€‚å¯ä»¥ä½¿ç”¨persist()æ–¹æ³•å¯¹ä¸€ä¸ªRDDæ ‡è®°ä¸ºæŒä¹…åŒ–ï¼Œä¹‹æ‰€ä»¥è¯´â€œæ ‡è®°ä¸ºæŒä¹…åŒ–â€ï¼Œæ˜¯å› ä¸ºå‡ºç°persist()è¯­å¥çš„åœ°æ–¹ï¼Œ<strong>å¹¶ä¸ä¼šé©¬ä¸Šè®¡ç®—ç”ŸæˆRDDå¹¶æŠŠå®ƒæŒä¹…åŒ–ï¼Œè€Œæ˜¯è¦ç­‰åˆ°é‡åˆ°ç¬¬ä¸€ä¸ªè¡ŒåŠ¨æ“ä½œè§¦å‘çœŸæ­£è®¡ç®—ä»¥å</strong>ï¼Œæ‰ä¼šæŠŠè®¡ç®—ç»“æœè¿›è¡ŒæŒä¹…åŒ–ï¼ŒæŒä¹…åŒ–åçš„RDDå°†ä¼šè¢«ä¿ç•™åœ¨è®¡ç®—èŠ‚ç‚¹çš„å†…å­˜ä¸­è¢«åé¢çš„è¡ŒåŠ¨æ“ä½œé‡å¤ä½¿ç”¨ã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> mp = textFile.map(line =&gt; line.split(<span class="string">&quot; &quot;</span>).size)</span><br><span class="line">mp: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">48</span>] at map at &lt;console&gt;:<span class="number">23</span></span><br><span class="line"></span><br><span class="line">scala&gt; mp.cache() <span class="comment">// ä¸ä¼šç¼“å­˜ mpï¼Œå› ä¸º mp è¿˜æ²¡æœ‰è®¡ç®—ç”Ÿæˆ</span></span><br><span class="line">res32: mp.<span class="keyword">type</span> = <span class="type">MapPartitionsRDD</span>[<span class="number">48</span>] at map at &lt;console&gt;:<span class="number">23</span></span><br><span class="line"></span><br><span class="line">scala&gt; mp.count() <span class="comment">// è®¡ç®— mpï¼Œå¹¶ä¸”ç¼“å­˜</span></span><br><span class="line">res33: <span class="type">Long</span> = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">scala&gt; mp.collect() <span class="comment">// é‡å¤ä½¿ç”¨ cache çš„ mp</span></span><br><span class="line">res34: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">7</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>



<p>å¦‚æœä½¿ç”¨é›†ç¾¤æ¨¡å¼æ‰“å° RDD çš„è¯ï¼Œä¸èƒ½ä½¿ç”¨  <code>rdd.foreach(println)</code> æˆ–è€…<code>rdd.map(println)</code>ï¼Œè€Œæ˜¯ <code>rdd.collect().foreach(println)</code> æˆ–è€…<code>rdd.collect().toke(100).foreach(println)</code></p>
<h3 id="é”®å€¼å¯¹-RDD"><a href="#é”®å€¼å¯¹-RDD" class="headerlink" title="é”®å€¼å¯¹ RDD"></a>é”®å€¼å¯¹ RDD</h3><p>é€šè¿‡ map å‡½æ•°åˆ›å»º kvRDD</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> pairRDD = lines.flatMap(line =&gt; line.split(<span class="string">&quot; &quot;</span>)).map(word =&gt; (word,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>



<p>transformation:</p>
<ul>
<li><p>reduceByKey</p>
</li>
<li><p>groupByKey</p>
</li>
<li><p>sortByKey</p>
</li>
<li><p>mapValues(func): ä½œç”¨äº (k, v) çš„ value çš„å‡½æ•°</p>
</li>
<li><p>join: Â (k, v1), (k, v2) &#x3D;&gt; (k, (v1, v2))</p>
</li>
<li><p>keys</p>
</li>
<li><p>values</p>
</li>
</ul>
<p>demoï¼šç»Ÿè®¡ kv çš„å¹³å‡å€¼</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;spark&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;hadoop&quot;</span>,<span class="number">6</span>),(<span class="string">&quot;hadoop&quot;</span>,<span class="number">4</span>),(<span class="string">&quot;spark&quot;</span>,<span class="number">6</span>)))</span><br><span class="line"></span><br><span class="line">rdd.mapValues(x =&gt; (x, <span class="number">1</span>)).reduceByKey((x, y) =&gt; (x._1 + y._1, x._2 + y._2)).mapValues(x =&gt; x._1 / x._2).collect()</span><br></pre></td></tr></table></figure>





<ul>
<li><p>API</p>
<ul>
<li><p>Transformations &#x3D;&gt; another RDD</p>
<ul>
<li>map, filter, union</li>
<li>groupByKey, reduceByKey, repartition</li>
</ul>
</li>
<li><p>Actions &#x3D;&gt; Lineage ä¸­æ–­</p>
<ul>
<li>count, collect, saveAsTextFile</li>
<li>foreach</li>
</ul>
</li>
<li><p>parallelize</p>
</li>
</ul>
</li>
<li><p>Source</p>
<ul>
<li><p>from storage</p>
<ul>
<li><p>HDFS <code>words = sc.textFile(&quot;hdfs://...&quot;)</code></p>
</li>
<li><p>local:</p>
</li>
<li><p>Kafka</p>
</li>
</ul>
</li>
<li><p>from another RDD</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">res = words.map(word =&gt; (word, <span class="number">1</span>)).reduceByKey((a, b) =&gt; a + b)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<p>æäº¤ä½œä¸šï¼š</p>
<ul>
<li><p><code>spark-shell</code></p>
</li>
<li><p><code>Spark-submit</code></p>
</li>
<li><p>narrow(pipeline): e.g. map</p>
</li>
<li><p>wide(shuffle): e.g. reduceByKey</p>
</li>
</ul>
<h2 id="å…±äº«å˜é‡"><a href="#å…±äº«å˜é‡" class="headerlink" title="å…±äº«å˜é‡"></a>å…±äº«å˜é‡</h2><p>å½“Sparkåœ¨é›†ç¾¤çš„å¤šä¸ªä¸åŒèŠ‚ç‚¹çš„å¤šä¸ªä»»åŠ¡ä¸Šå¹¶è¡Œè¿è¡Œä¸€ä¸ªå‡½æ•°æ—¶ï¼Œå®ƒä¼šæŠŠå‡½æ•°ä¸­æ¶‰åŠåˆ°çš„<strong>æ¯ä¸ªå˜é‡</strong>ï¼Œåœ¨æ¯ä¸ªä»»åŠ¡ä¸Šéƒ½ç”Ÿæˆä¸€ä¸ª<strong>å‰¯æœ¬</strong>ã€‚</p>
<p>é—®é¢˜ï¼šæœ‰æ—¶å€™ï¼Œéœ€è¦åœ¨å¤šä¸ªä»»åŠ¡ä¹‹é—´å…±äº«å˜é‡ã€‚</p>
<p>è§£å†³ï¼šå¼•å…¥ å¹¿æ’­å˜é‡ï¼Œç´¯åŠ å™¨</p>
<h3 id="å¹¿æ’­å˜é‡"><a href="#å¹¿æ’­å˜é‡" class="headerlink" title="å¹¿æ’­å˜é‡"></a>å¹¿æ’­å˜é‡</h3><blockquote>
<p><strong>åºåˆ—åŒ–</strong>æ˜¯ Javaå¯¹è±¡ &#x3D;&gt; å­—èŠ‚åºåˆ— çš„è¿‡ç¨‹ã€‚</p>
<p><strong>ååºåˆ—åŒ–</strong>æ˜¯ å­—èŠ‚åºåˆ— &#x3D;&gt; Javaå¯¹è±¡ çš„è¿‡ç¨‹ã€‚</p>
<p>ä¸»è¦ç”¨äºä¸¤ä¸ª java è¿›ç¨‹è¿›è¡Œé€šä¿¡ï¼Œä¼ è¾“ java å¯¹è±¡ä¼ é€ã€‚</p>
<p>å¥½å¤„ï¼š</p>
<ul>
<li>æ•°æ®æŒä¹…åŒ–</li>
<li>åºåˆ—åŒ–å®ç°è¿œç¨‹é€šä¿¡</li>
</ul>
<p><a class="link" target="_blank" rel="noopener" href="https://juejin.cn/post/7064942360106369054">åºåˆ—åŒ– &amp; ååºåˆ—åŒ–<i class="fas fa-external-link-alt"></i></a></p>
</blockquote>
<p>åœ¨æ¯ä¸ªæœºå™¨ä¸Š<strong>ç¼“å­˜</strong>ä¸€ä¸ª<strong>åªè¯»</strong>çš„å˜é‡ï¼Œ<strong>è€Œä¸æ˜¯</strong>ä¸ºæœºå™¨ä¸Šçš„æ¯ä¸ªä»»åŠ¡éƒ½ç”Ÿæˆä¸€ä¸ªå‰¯æœ¬ã€‚</p>
<p>æ˜¾å¼åˆ›å»ºå¹¿æ’­å˜é‡çš„åœºæ™¯ï¼šå½“è·¨è¶Šå¤šä¸ªé˜¶æ®µçš„é‚£äº›ä»»åŠ¡éœ€è¦ç›¸åŒçš„æ•°æ®ã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> broadcastVar = sc.broadcast(<span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">broadcastVar.value</span><br></pre></td></tr></table></figure>

<p>SparkContext.broadcast(v) ä¹‹åï¼Œé›†ç¾¤çš„å‡½æ•°éƒ½éœ€è¦ä½¿ç”¨ å¹¿æ’­å˜é‡ çš„å€¼ï¼Œè€Œä¸æ˜¯åŸå€¼ã€‚</p>
<h3 id="ç´¯åŠ å™¨"><a href="#ç´¯åŠ å™¨" class="headerlink" title="ç´¯åŠ å™¨"></a>ç´¯åŠ å™¨</h3><p>ä¸€ä¸ªæ•°å€¼å‹çš„ç´¯åŠ å™¨ï¼Œå¯ä»¥é€šè¿‡è°ƒç”¨SparkContext.longAccumulator()æˆ–è€…SparkContext.doubleAccumulator()æ¥åˆ›å»ºã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> accum = sc.longAccumulator(<span class="string">&quot;My Accumulator&quot;</span>)</span><br><span class="line"></span><br><span class="line">sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)).foreach(x =&gt; accum.add(x))</span><br><span class="line"></span><br><span class="line">accum.value</span><br></pre></td></tr></table></figure>



<h2 id="Spark-SQL"><a href="#Spark-SQL" class="headerlink" title="Spark SQL"></a>Spark SQL</h2><p>DataFrame å’Œ RDD çš„åŒºåˆ«ï¼š</p>
<ul>
<li>RDD æ˜¯åˆ†å¸ƒå¼ Java å¯¹è±¡é›†åˆï¼Œå¯¹è±¡å†…éƒ¨ç»“æ„å¯¹äº RDD ä¸å¯çŸ¥ã€‚</li>
<li>DataFrame æ˜¯ä»¥ RDD ä¸ºåŸºç¡€çš„åˆ†å¸ƒå¼æ•°æ®é›†(åˆ†å¸ƒå¼ Row å¯¹è±¡é›†åˆ)ï¼Œæä¾›è¯¦ç»†çš„ç»“æ„ä¿¡æ¯</li>
</ul>
<p>åŒæ—¶ï¼š</p>
<p>DataFrame ä¹Ÿé‡‡ç”¨æƒ°æ€§æœºåˆ¶ï¼Œå’Œ RDD çš„å¤„ç†é€»è¾‘ä¸€æ ·ã€‚</p>
<h3 id="DF-åˆ›å»º-amp-ä¿å­˜"><a href="#DF-åˆ›å»º-amp-ä¿å­˜" class="headerlink" title="DF åˆ›å»º &amp; ä¿å­˜"></a>DF åˆ›å»º &amp; ä¿å­˜</h3><blockquote>
<p>åˆ›å»º</p>
</blockquote>
<ul>
<li>è¯»å–æ–‡ä»¶</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> peopleDF = spark.read.format(<span class="string">&quot;json&quot;</span>).load(<span class="string">&quot;file:///people.json&quot;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>ä½¿ç”¨ rdd åˆ›å»º df</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> filename = <span class="string">&quot;hdfs://localhost:8020/user/spark/people.txt&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> peopleRDD = spark.sparkContext.textFile(filename)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The schema is encoded in a string</span></span><br><span class="line">    <span class="keyword">val</span> schemaString = <span class="string">&quot;name age&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Generate the schema based on the string of schema</span></span><br><span class="line">    <span class="keyword">val</span> fields = schemaString.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">      .map(fieldName =&gt; <span class="type">StructField</span>(fieldName, <span class="type">StringType</span>, nullable = <span class="literal">true</span>))</span><br><span class="line">    <span class="keyword">val</span> schema = <span class="type">StructType</span>(fields)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Convert records of the RDD (people) to Rows</span></span><br><span class="line">    <span class="keyword">val</span> rowRDD = peopleRDD</span><br><span class="line">      .map(_.split(<span class="string">&quot;,&quot;</span>))</span><br><span class="line">      .map(attributes =&gt; <span class="type">Row</span>(attributes(<span class="number">0</span>), attributes(<span class="number">1</span>).trim))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Apply the schema to the RDD</span></span><br><span class="line">    <span class="keyword">val</span> peopleDF = spark.createDataFrame(rowRDD, schema)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Creates a temporary view using the DataFrame</span></span><br><span class="line">    peopleDF.createOrReplaceTempView(<span class="string">&quot;people&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// SQL can be run over a temporary view created using DataFrames</span></span><br><span class="line">    <span class="keyword">val</span> results = spark.sql(<span class="string">&quot;SELECT name FROM people&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// The results of SQL queries are DataFrames and support all the normal RDD operations</span></span><br><span class="line">    <span class="comment">// The columns of a row in the result can be accessed by field index or by field name</span></span><br><span class="line">    results.map(attributes =&gt; <span class="string">&quot;Name: &quot;</span> + attributes(<span class="number">0</span>)).show()</span><br></pre></td></tr></table></figure>

<ol>
<li>è¯»å– rdd &#x3D;&gt; rowRDD</li>
<li>åˆ›å»º schema</li>
<li>åˆ›å»º df</li>
</ol>
<blockquote>
<p>ä¿å­˜</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">peopleDF.select(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;age&quot;</span>).write.format(<span class="string">&quot;csv&quot;</span>).save(<span class="string">&quot;file:///newpeople.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>write.format()æ”¯æŒè¾“å‡º json,parquet, jdbc, orc, libsvm, csv, textç­‰æ ¼å¼æ–‡ä»¶ï¼Œå¦‚æœè¦è¾“å‡ºæ–‡æœ¬æ–‡ä»¶ï¼Œå¯ä»¥é‡‡ç”¨write.format(â€œtextâ€)ï¼Œä½†æ˜¯ï¼Œéœ€è¦æ³¨æ„ï¼Œåªæœ‰select()ä¸­åªå­˜åœ¨ä¸€ä¸ªåˆ—æ—¶ï¼Œæ‰å…è®¸ä¿å­˜æˆæ–‡æœ¬æ–‡ä»¶ï¼Œå¦‚æœå­˜åœ¨ä¸¤ä¸ªåˆ—ï¼Œæ¯”å¦‚select(â€œnameâ€, â€œageâ€)ï¼Œå°±ä¸èƒ½ä¿å­˜æˆæ–‡æœ¬æ–‡ä»¶ã€‚</p>
<h3 id="è·å–-mysql-æ•°æ®"><a href="#è·å–-mysql-æ•°æ®" class="headerlink" title="è·å– mysql æ•°æ®"></a>è·å– mysql æ•°æ®</h3><p><a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/hjw199089/article/details/53522554">shell &amp; ç¨‹åºæ–¹æ³•ä½¿ç”¨ JDBC è¯»å– mysql æ•°æ®<i class="fas fa-external-link-alt"></i></a></p>
<ul>
<li><p>å®‰è£… JDBC</p>
</li>
<li><p>å¯åŠ¨ shell çš„æ—¶å€™æŒ‡å®š jdbc</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spark-shell \</span><br><span class="line">--jars $SPARK_HOME/jars/mysql-connector-j-8.0.31/mysql-connector-j-8.0.31.jar \</span><br><span class="line">--driver-class-path $SPARK_HOME/jars/mysql-connector-j-8.0.31/mysql-connector-j-8.0.31.jar</span><br></pre></td></tr></table></figure>
</li>
<li><p>è·å– mysql æ•°æ®</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> jdbcDF = spark.read.format(<span class="string">&quot;jdbc&quot;</span>).option(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://localhost:3306/spark&quot;</span>).option(<span class="string">&quot;driver&quot;</span>,<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>).option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;student&quot;</span>).option(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;root&quot;</span>).option(<span class="string">&quot;password&quot;</span>, <span class="string">&quot;123&quot;</span>).load()</span><br><span class="line">jdbcDF: org.apache.spark.sql.<span class="type">DataFrame</span> = [id: int, name: string ... <span class="number">2</span> more fields]</span><br><span class="line"></span><br><span class="line">scala&gt; jdbcDF.show()</span><br><span class="line">+---+--------+------+---+</span><br><span class="line">| id|    name|gender|age|</span><br><span class="line">+---+--------+------+---+</span><br><span class="line">|  <span class="number">1</span>| <span class="type">Xueqian</span>|     <span class="type">F</span>| <span class="number">23</span>|</span><br><span class="line">|  <span class="number">2</span>|<span class="type">Weiliang</span>|     <span class="type">M</span>| <span class="number">24</span>|</span><br><span class="line">+---+--------+------+---+</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Spark-Streaming"><a href="#Spark-Streaming" class="headerlink" title="Spark Streaming"></a>Spark Streaming</h2><p><img src="https://spark.apache.org/docs/latest/img/streaming-flow.png"></p>
<p>å°†è¾“å…¥æµæŒ‰ç…§æ—¶é—´ç‰‡è¿›è¡Œæ‹†åˆ†ï¼ˆç§’çº§ï¼‰ï¼Œç„¶åè¿›è¿‡ spark å¼•æ“æ‰¹å¤„ç†ã€‚</p>
<p>DStreamï¼ˆDiscretized Streamï¼Œç¦»æ•£åŒ–æ•°æ®æµï¼‰ï¼Œè¡¨ç¤ºè¿ç»­ä¸æ–­çš„æ•°æ®æµã€‚</p>
<h2 id="æ•°æ®åˆ†åŒºå™¨-rddå¦‚ä½•å­˜å‚¨"><a href="#æ•°æ®åˆ†åŒºå™¨-rddå¦‚ä½•å­˜å‚¨" class="headerlink" title="æ•°æ®åˆ†åŒºå™¨ rddå¦‚ä½•å­˜å‚¨"></a>æ•°æ®åˆ†åŒºå™¨ rddå¦‚ä½•å­˜å‚¨</h2><h2 id="Spark-æºç é˜…è¯»"><a href="#Spark-æºç é˜…è¯»" class="headerlink" title="Spark æºç é˜…è¯»"></a>Spark æºç é˜…è¯»</h2><h3 id="RDD-1"><a href="#RDD-1" class="headerlink" title="RDD"></a>RDD</h3><ul>
<li>partitions åˆ—è¡¨</li>
<li>dependencies åˆ—è¡¨</li>
<li>ä¸€äº›å‡½æ•°ï¼Œe.g. map</li>
</ul>
<h4 id="RDD-åˆ†åŒº"><a href="#RDD-åˆ†åŒº" class="headerlink" title="RDD åˆ†åŒº"></a>RDD åˆ†åŒº</h4><p>åˆ†åŒºæ¥å£å®šä¹‰ï¼Œå®ç° <code>Serializable</code> å¯ä»¥å®ç°åºåˆ—åŒ–æ“ä½œã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">trait</span> <span class="title">Partition</span> <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Get the partition&#x27;s index within its parent RDD</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">index</span></span>: <span class="type">Int</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// A better default implementation of HashCode</span></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hashCode</span></span>(): <span class="type">Int</span> = index</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">equals</span></span>(other: <span class="type">Any</span>): <span class="type">Boolean</span> = <span class="keyword">super</span>.equals(other)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>RDDï¼š</p>
<ul>
<li>åŒ…å«ä¸€ä¸ª <code>partitions</code> çš„ listï¼Œå¤–ç•Œåªèƒ½é€šè¿‡ <code>partitions</code> æ–¹æ³•æ¥è®¿é—®ï¼Œå­ç±»éœ€è¦é‡å†™ <code>getPartitions</code> æ–¹æ³•</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@transient</span> <span class="keyword">private</span> <span class="keyword">var</span> partitions_ : <span class="type">Array</span>[<span class="type">Partition</span>] = <span class="literal">null</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Implemented by subclasses to return the set of partitions in this RDD. This method will only</span></span><br><span class="line"><span class="comment">   * be called once, so it is safe to implement a time-consuming computation in it.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">getPartitions</span></span>: <span class="type">Array</span>[<span class="type">Partition</span>]</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Get the array of partitions of this RDD, taking into account whether the</span></span><br><span class="line"><span class="comment">   * RDD is checkpointed or not.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">partitions</span></span>: <span class="type">Array</span>[<span class="type">Partition</span>] = &#123;</span><br><span class="line">    checkpointRDD.map(_.partitions).getOrElse &#123;</span><br><span class="line">      <span class="keyword">if</span> (partitions_ == <span class="literal">null</span>) &#123;</span><br><span class="line">        partitions_ = getPartitions</span><br><span class="line">      &#125;</span><br><span class="line">      partitions_</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>



<h5 id="RDD-åˆ†åŒºä¸ªæ•°åˆ†é…åŸåˆ™"><a href="#RDD-åˆ†åŒºä¸ªæ•°åˆ†é…åŸåˆ™" class="headerlink" title="RDD åˆ†åŒºä¸ªæ•°åˆ†é…åŸåˆ™"></a>RDD åˆ†åŒºä¸ªæ•°åˆ†é…åŸåˆ™</h5><p>å°½å¯èƒ½ä½¿å¾—åˆ†åŒºçš„ä¸ªæ•°ï¼Œç­‰äºé›†ç¾¤æ ¸å¿ƒæ•°ç›®ã€‚</p>
<p><strong>è½¬æ¢æ“ä½œ</strong>å¾—åˆ°çš„ RDD çš„åˆ†åŒºä¸ªæ•°ï¼š</p>
<ul>
<li>narrowï¼šå­ RDD ç”±<strong>çˆ¶ RDD åˆ†åŒºä¸ªæ•°</strong>å†³å®š</li>
<li>Shuffleï¼šä¾èµ–ç”±å­ RDD <strong>åˆ†åŒºå™¨</strong>å†³å®š</li>
</ul>
<p><code>parallelize</code> æ–¹æ³•ï¼Œé€šè¿‡ <code>defaultParallelism</code> å‚æ•°æ¥å†³å®šåˆ†åŒºå¤§å°ã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parallelize</span></span>[<span class="type">T</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    seq: <span class="type">Seq</span>[<span class="type">T</span>],</span><br><span class="line">    numSlices: <span class="type">Int</span> = defaultParallelism): <span class="type">RDD</span>[<span class="type">T</span>] = withScope &#123;</span><br><span class="line">  assertNotStopped()</span><br><span class="line">  <span class="keyword">new</span> <span class="type">ParallelCollectionRDD</span>[<span class="type">T</span>](<span class="keyword">this</span>, seq, numSlices, <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Seq</span>[<span class="type">String</span>]]())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>defaultParallelism</code> å‚æ•°ç”± spark ä¸åŒçš„æ¨¡å¼æ¥ç¡®å®šï¼Œä¾‹å¦‚ <code>SingleCoreMockBackend</code> åªæœ‰ä¸€ä¸ª <code>core</code></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">SingleCoreMockBackend</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="class">  conf: <span class="type">SparkConf</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">  taskScheduler: <span class="type">TaskSchedulerImpl</span></span>) <span class="keyword">extends</span> <span class="title">MockBackend</span>(<span class="params">conf, taskScheduler</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> cores = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">defaultParallelism</span></span>(): <span class="type">Int</span> = conf.getInt(<span class="string">&quot;spark.default.parallelism&quot;</span>, cores)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p><code>textFile</code> æ–¹æ³•ï¼Œæœ€å°æ˜¯ 2</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">textFile</span></span>(</span><br><span class="line">    path: <span class="type">String</span>,</span><br><span class="line">    minPartitions: <span class="type">Int</span> = defaultMinPartitions): <span class="type">RDD</span>[<span class="type">String</span>] = withScope &#123;</span><br><span class="line">  assertNotStopped()</span><br><span class="line">  hadoopFile(path, classOf[<span class="type">TextInputFormat</span>], classOf[<span class="type">LongWritable</span>], classOf[<span class="type">Text</span>],</span><br><span class="line">    minPartitions).map(pair =&gt; pair._2.toString).setName(path)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">defaultMinPartitions</span></span>: <span class="type">Int</span> = math.min(defaultParallelism, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>





<h5 id="RDD-åˆ†åŒºå†…è®°å½•ä¸ªæ•°"><a href="#RDD-åˆ†åŒºå†…è®°å½•ä¸ªæ•°" class="headerlink" title="RDD åˆ†åŒºå†…è®°å½•ä¸ªæ•°"></a>RDD åˆ†åŒºå†…è®°å½•ä¸ªæ•°</h5><p>å°½å¯èƒ½ä½¿åŒä¸€ RDD ä¸åŒåˆ†åŒºå†…çš„è®°å½•çš„æ•°é‡ä¸€è‡´ã€‚</p>
<ul>
<li>narrowï¼šä¾èµ–äº<strong>çˆ¶ RDD ä¸­ç›¸åŒç¼–å·åˆ†åŒº</strong>æ˜¯å¦‚ä½•è¿›è¡Œæ•°æ®åˆ†é…çš„</li>
<li>shuffleï¼šä¾èµ–äºé€‰æ‹©çš„<strong>åˆ†åŒºå™¨</strong>ï¼Œå“ˆå¸Œåˆ†åŒºå™¨æ— æ³•ä¿è¯æ•°æ®è¢«å¹³å‡åˆ†é…åˆ°å„ä¸ªåˆ†åŒºï¼Œè€ŒèŒƒå›´åˆ†åŒºå™¨åˆ™èƒ½åšåˆ°è¿™ä¸€ç‚¹ã€‚</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">object</span> <span class="title">ParallelCollectionRDD</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Slice a collection into numSlices sub-collections. One extra thing we do here is to treat Range</span></span><br><span class="line"><span class="comment">   * collections specially, encoding the slices as other Ranges to minimize memory cost. This makes</span></span><br><span class="line"><span class="comment">   * it efficient to run Spark over RDDs representing large sets of numbers. And if the collection</span></span><br><span class="line"><span class="comment">   * is an inclusive Range, we use inclusive range for the last slice.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">slice</span></span>[<span class="type">T</span>: <span class="type">ClassTag</span>](seq: <span class="type">Seq</span>[<span class="type">T</span>], numSlices: <span class="type">Int</span>): <span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">T</span>]] = &#123;</span><br><span class="line">    <span class="keyword">if</span> (numSlices &lt; <span class="number">1</span>) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">&quot;Positive number of partitions required&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Sequences need to be sliced at the same set of index positions for operations</span></span><br><span class="line">    <span class="comment">// like RDD.zip() to behave as expected</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">positions</span></span>(length: <span class="type">Long</span>, numSlices: <span class="type">Int</span>): <span class="type">Iterator</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = &#123;</span><br><span class="line">      (<span class="number">0</span> until numSlices).iterator.map &#123; i =&gt;</span><br><span class="line">        <span class="keyword">val</span> start = ((i * length) / numSlices).toInt</span><br><span class="line">        <span class="keyword">val</span> end = (((i + <span class="number">1</span>) * length) / numSlices).toInt</span><br><span class="line">        (start, end)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    seq <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> r: <span class="type">Range</span> =&gt;</span><br><span class="line">        positions(r.length, numSlices).zipWithIndex.map &#123; <span class="keyword">case</span> ((start, end), index) =&gt;</span><br><span class="line">          <span class="comment">// If the range is inclusive, use inclusive range for the last slice</span></span><br><span class="line">          <span class="keyword">if</span> (r.isInclusive &amp;&amp; index == numSlices - <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">new</span> <span class="type">Range</span>.<span class="type">Inclusive</span>(r.start + start * r.step, r.end, r.step)</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">new</span> <span class="type">Range</span>.<span class="type">Inclusive</span>(r.start + start * r.step, r.start + (end - <span class="number">1</span>) * r.step, r.step)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;.toSeq.asInstanceOf[<span class="type">Seq</span>[<span class="type">Seq</span>[<span class="type">T</span>]]]</span><br><span class="line">      <span class="keyword">case</span> nr: <span class="type">NumericRange</span>[<span class="type">T</span>] =&gt;</span><br><span class="line">        <span class="comment">// For ranges of Long, Double, BigInteger, etc</span></span><br><span class="line">        <span class="keyword">val</span> slices = <span class="keyword">new</span> <span class="type">ArrayBuffer</span>[<span class="type">Seq</span>[<span class="type">T</span>]](numSlices)</span><br><span class="line">        <span class="keyword">var</span> r = nr</span><br><span class="line">        <span class="keyword">for</span> ((start, end) &lt;- positions(nr.length, numSlices)) &#123;</span><br><span class="line">          <span class="keyword">val</span> sliceSize = end - start</span><br><span class="line">          slices += r.take(sliceSize).asInstanceOf[<span class="type">Seq</span>[<span class="type">T</span>]]</span><br><span class="line">          r = r.drop(sliceSize)</span><br><span class="line">        &#125;</span><br><span class="line">        slices.toSeq</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        <span class="keyword">val</span> array = seq.toArray <span class="comment">// To prevent O(n^2) operations for List etc</span></span><br><span class="line">        positions(array.length, numSlices).map &#123; <span class="keyword">case</span> (start, end) =&gt;</span><br><span class="line">            array.slice(start, end).toSeq</span><br><span class="line">        &#125;.toSeq</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>å°±æ˜¯æ„é€ ç­‰é•¿çš„åˆ†åŒºã€‚</p>
<h4 id="RDD-ä¾èµ–"><a href="#RDD-ä¾èµ–" class="headerlink" title="RDD ä¾èµ–"></a>RDD ä¾èµ–</h4><p>åœ¨å¤–éƒ¨é€šå¸¸æŠŠè®°å½•çš„ä¿¡æ¯æˆä¸ºè¡€ç¼˜å…³ç³»ã€‚åœ¨å†…éƒ¨è®°å½•åˆ™æ˜¯ RDD ä¹‹é—´çš„ä¾èµ– Dependancyã€‚</p>
<p>ä¾èµ–åªä¿å­˜åœ¨<strong>çˆ¶ RDD</strong> ä¸­ã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@DeveloperApi</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Dependency</span>[<span class="type">T</span>] <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">rdd</span></span>: <span class="type">RDD</span>[<span class="type">T</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<blockquote>
<p>ä¾èµ–çš„åˆ†ç±»</p>
</blockquote>
<p>ä¾èµ–å…³ç³»æŒ‡ä¸¤ä¸ª RDD ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚å¦‚æœä¸€æ¬¡è½¬æ¢ä¸­åŒ…å«å¤šä¸ªçˆ¶ä¾èµ–ï¼Œåˆ™<strong>å¯èƒ½åŒæ—¶å­˜åœ¨ narrow å’Œ wild</strong></p>
<p><img src="https://ihainan.gitbooks.io/spark-source-code/content/media/images/section1/RDDDependencies/ComplexDependencies.png"></p>
<h5 id="narrow"><a href="#narrow" class="headerlink" title="narrow"></a>narrow</h5><p>Narrow å®ç°åœ¨ <code>NarrowDependency</code> ä¸­ã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@DeveloperApi</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">NarrowDependency</span>[<span class="type">T</span>](<span class="params">_rdd: <span class="type">RDD</span>[<span class="type">T</span>]</span>) <span class="keyword">extends</span> <span class="title">Dependency</span>[<span class="type">T</span>] </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Get the parent partitions for a child partition.</span></span><br><span class="line"><span class="comment">   * ç”¨äºè·å–åˆ†åŒºæ¥æºäºçˆ¶ RDD ä¸­çš„å“ªä¸€ä¸ªåˆ†åŒºï¼Œåªä¼šè¿”å›ä¸€ä¸ªå…ƒç´ </span></span><br><span class="line"><span class="comment">   * @param partitionId a partition of the child RDD</span></span><br><span class="line"><span class="comment">   * @return the partitions of the parent RDD that the child partition depends upon</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getParents</span></span>(partitionId: <span class="type">Int</span>): <span class="type">Seq</span>[<span class="type">Int</span>]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">rdd</span></span>: <span class="type">RDD</span>[<span class="type">T</span>] = _rdd</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>narrow å¯ä»¥è¿›ä¸€æ­¥åˆ†ä¸º <strong>ä¸€å¯¹ä¸€ä¾èµ–</strong> å’Œ <strong>èŒƒå›´ä¾èµ–</strong></p>
<blockquote>
<p>ä¸€å¯¹ä¸€ä¾èµ–</p>
</blockquote>
<p>ä¸€å¯¹ä¸€ä¾èµ–è¡¨ç¤ºå­ RDD åˆ†åŒºçš„ç¼–å·ä¸çˆ¶ RDD åˆ†åŒºçš„ç¼–å·å®Œå…¨ä¸€è‡´çš„æƒ…å†µã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@DeveloperApi</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OneToOneDependency</span>[<span class="type">T</span>](<span class="params">rdd: <span class="type">RDD</span>[<span class="type">T</span>]</span>) <span class="keyword">extends</span> <span class="title">NarrowDependency</span>[<span class="type">T</span>](<span class="params">rdd</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getParents</span></span>(partitionId: <span class="type">Int</span>) = <span class="type">List</span>(partitionId)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<blockquote>
<p>èŒƒå›´ä¾èµ–</p>
</blockquote>
<p>èŒƒå›´ä¾èµ–æ˜¯å­ RDD æœ‰çˆ¶ RDDï¼Œä½†æ˜¯åˆ†åŒºä¿¡æ¯è¿˜æ˜¯ä¸€å¯¹ä¸€çš„ã€‚å¦‚å›¾ï¼š</p>
<p><img src="https://ihainan.gitbooks.io/spark-source-code/content/media/images/section1/RDDDependencies/RangeDependencyExample.png"></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * :: DeveloperApi ::</span></span><br><span class="line"><span class="comment"> * Represents a one-to-one dependency between ranges of partitions in the parent and child RDDs.</span></span><br><span class="line"><span class="comment"> * @param rdd the parent RDD</span></span><br><span class="line"><span class="comment"> * @param inStart the start of the range in the parent RDD</span></span><br><span class="line"><span class="comment"> * @param outStart the start of the range in the child RDD</span></span><br><span class="line"><span class="comment"> * @param length the length of the range</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@DeveloperApi</span></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">RangeDependency</span>[<span class="type">T</span>](<span class="params">rdd: <span class="type">RDD</span>[<span class="type">T</span>], inStart: <span class="type">Int</span>, outStart: <span class="type">Int</span>, length: <span class="type">Int</span></span>)</span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">NarrowDependency</span>[<span class="type">T</span>](rdd) &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getParents</span></span>(partitionId: <span class="type">Int</span>) = &#123;</span><br><span class="line">      <span class="comment">// å¦‚æœåœ¨å­åˆ†åŒºä¸­ï¼Œè¿”å›å¯¹åº”çˆ¶åˆ†åŒº</span></span><br><span class="line">    <span class="keyword">if</span> (partitionId &gt;= outStart &amp;&amp; partitionId &lt; outStart + length) &#123;</span><br><span class="line">      <span class="type">List</span>(partitionId - outStart + inStart)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// å¦åˆ™æ˜¯ Nil</span></span><br><span class="line">      <span class="type">Nil</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h5 id="shuffle"><a href="#shuffle" class="headerlink" title="shuffle"></a>shuffle</h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * :: DeveloperApi ::</span></span><br><span class="line"><span class="comment"> * Represents a dependency on the output of a shuffle stage. Note that in the case of shuffle,</span></span><br><span class="line"><span class="comment"> * the RDD is transient since we don&#x27;t need it on the executor side.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param _rdd the parent RDD</span></span><br><span class="line"><span class="comment"> * @param partitioner partitioner used to partition the shuffle output</span></span><br><span class="line"><span class="comment"> * @param serializer [[org.apache.spark.serializer.Serializer Serializer]] to use. If set to None,</span></span><br><span class="line"><span class="comment"> *                   the default serializer, as specified by `spark.serializer` config option, will</span></span><br><span class="line"><span class="comment"> *                   be used.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@DeveloperApi</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ShuffleDependency</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">C</span>](<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="class">    @transient _rdd: <span class="type">RDD</span>[_ &lt;: <span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>]],</span></span></span><br><span class="line"><span class="params"><span class="class">val partitioner: <span class="type">Partitioner</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">val serializer: <span class="type">Option</span>[<span class="type">Serializer</span>] = <span class="type">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">    val keyOrdering: <span class="type">Option</span>[<span class="type">Ordering</span>[<span class="type">K</span>]] = <span class="type">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">    val aggregator: <span class="type">Option</span>[<span class="type">Aggregator</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">C</span>]] = <span class="type">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">    val mapSideCombine: <span class="type">Boolean</span> = false</span>)</span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">Dependency</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>]] &#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">rdd</span> </span>= _rdd.asInstanceOf[<span class="type">RDD</span>[<span class="type">Product2</span>[<span class="type">K</span>, <span class="type">V</span>]]]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> shuffleId: <span class="type">Int</span> = _rdd.context.newShuffleId()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> shuffleHandle: <span class="type">ShuffleHandle</span> = _rdd.context.env.shuffleManager.registerShuffle(</span><br><span class="line">      shuffleId, _rdd.partitions.size, <span class="keyword">this</span>)</span><br><span class="line"></span><br><span class="line">  _rdd.sparkContext.cleaner.foreach(_.registerShuffleForCleanup(<span class="keyword">this</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h4 id="RDD-æŒä¹…åŒ–"><a href="#RDD-æŒä¹…åŒ–" class="headerlink" title="RDD æŒä¹…åŒ–"></a>RDD æŒä¹…åŒ–</h4><p>Spark é€Ÿåº¦éå¸¸å¿«çš„åŸå› ä¹‹ä¸€ï¼Œå°±æ˜¯åœ¨ä¸åŒæ“ä½œä¸­<strong>å¯ä»¥åœ¨å†…å­˜ä¸­æŒä¹…åŒ–æˆ–ç¼“å­˜ä¸ªæ•°æ®é›†</strong>ã€‚</p>
<p>ç¼“å­˜æ˜¯ Spark æ„å»º <code>è¿­ä»£å¼ç®—æ³•</code> å’Œ <code>å¿«é€Ÿäº¤äº’å¼æŸ¥è¯¢</code> çš„å…³é”®ã€‚</p>
<p>å¦‚æœä¸€ä¸ªæœ‰æŒä¹…åŒ–æ•°æ®çš„èŠ‚ç‚¹<strong>å‘ç”Ÿæ•…éšœ</strong>ï¼ŒSpark ä¼šåœ¨éœ€è¦<strong>ç”¨åˆ°ç¼“å­˜çš„æ•°æ®æ—¶é‡ç®—ä¸¢å¤±çš„æ•°æ®åˆ†åŒº</strong>ã€‚å¦‚æœå¸Œæœ›èŠ‚ç‚¹æ•…éšœçš„æƒ…å†µä¸ä¼šæ‹–ç´¯æˆ‘ä»¬çš„æ‰§è¡Œé€Ÿåº¦ï¼Œä¹Ÿå¯ä»¥æŠŠæ•°æ®<strong>å¤‡ä»½åˆ°å¤šä¸ªèŠ‚ç‚¹</strong>ä¸Šã€‚</p>
<p>ä¸¤ç§æŒä¹…åŒ–æ“ä½œï¼š</p>
<ul>
<li>persist(StorageLevel)</li>
<li>cacheï¼Œ cache å°±ç›¸å½“äº MEMORY_ONLY çš„ persist</li>
</ul>
<h5 id="RDD-ç¼“å­˜æ–¹å¼"><a href="#RDD-ç¼“å­˜æ–¹å¼" class="headerlink" title="RDD ç¼“å­˜æ–¹å¼"></a>RDD ç¼“å­˜æ–¹å¼</h5><p>[[å†…å­˜ç®¡ç†]] å¯ä»¥æŸ¥çœ‹ on-heap å’Œ off-heap å†…å­˜çš„ä¼˜ç¼ºç‚¹ã€‚</p>
<p>é»˜è®¤æƒ…å†µä¸‹ <code>persist()</code> ä¼šæŠŠæ•°æ®ä»¥åºåˆ—åŒ–çš„å½¢å¼ç¼“å­˜åœ¨ JVM çš„å †ç©ºé—´ä¸­ã€‚</p>
<p>è¿™ä¸¤ä¸ªæ–¹æ³•å¹¶<strong>ä¸æ˜¯è¢«è°ƒç”¨æ—¶ç«‹å³ç¼“å­˜</strong>ï¼Œè€Œæ˜¯è§¦å‘åé¢çš„ <strong>action</strong> æ—¶ï¼Œè¯¥ RDD å°†ä¼šè¢«ç¼“å­˜åœ¨è®¡ç®—èŠ‚ç‚¹çš„å†…å­˜ä¸­ï¼Œå¹¶ä¾›åé¢é‡ç”¨ã€‚</p>
<p>åœ¨å­˜å‚¨çº§åˆ«çš„æœ«å°¾åŠ ä¸Š <code>_2</code> æ¥æŠŠæŒä¹…åŒ–æ•°æ®å­˜ä¸ºä¸¤ä»½ã€‚ä¾‹å¦‚ <code>DISK_ONLY_2</code></p>
<p><img src="https://s2.ax1x.com/2019/04/26/Enf9Nn.png" alt="storage level"></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">StorageLevel</span> </span>&#123;  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">NONE</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>)  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">DISK_ONLY</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>)  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">DISK_ONLY_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">DISK_ONLY_3</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">3</span>)  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>)  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">2</span>)  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_SER</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>)  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_SER_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>)  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">2</span>)  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_SER</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>)  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_SER_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)  </span><br><span class="line">  <span class="keyword">val</span> <span class="type">OFF_HEAP</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="persist-cache-unpersist"><a href="#persist-cache-unpersist" class="headerlink" title="persist, cache, unpersist"></a>persist, cache, unpersist</h5><blockquote>
<p>persist and cache</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// cache() ç­‰åŒäº persist() ç­‰åŒäº persist(StorageLevel.MEMORY_ONLY) ï¼Œä¹Ÿå°±æ˜¯ä»…ç¼“å­˜äºå­˜å‚¨å†…å­˜ä¸­ã€‚</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cache</span></span>(): <span class="keyword">this</span>.<span class="keyword">type</span> = persist()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">persist</span></span>(): <span class="keyword">this</span>.<span class="keyword">type</span> = persist(<span class="type">StorageLevel</span>.<span class="type">MEMORY_ONLY</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ç¼“å­˜çº§åˆ«ï¼Œç”±5ä¸ªå‚æ•°ç»„æˆ</span></span><br><span class="line"><span class="keyword">new</span> <span class="type">StorageLevel</span>(useDisk, useMemory, useOffHeap, deserialized, replication))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">persist</span></span>(newLevel: <span class="type">StorageLevel</span>): <span class="keyword">this</span>.<span class="keyword">type</span> = &#123;</span><br><span class="line">  <span class="comment">// isLocallyCheckpointed æ–¹æ³• åˆ¤æ–­è¯¥RDDæ˜¯å¦å·²ç»æ ‡è®°ä¸º checkpointï¼Œæ³¨æ„ä¸æ˜¯cache</span></span><br><span class="line">  <span class="keyword">if</span> (isLocallyCheckpointed) &#123;</span><br><span class="line">    persist(<span class="type">LocalRDDCheckpointData</span>.transformStorageLevel(newLevel), allowOverride = <span class="literal">true</span>)</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    persist(newLevel, allowOverride = <span class="literal">false</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">persist</span></span>(newLevel: <span class="type">StorageLevel</span>, allowOverride: <span class="type">Boolean</span>): <span class="keyword">this</span>.<span class="keyword">type</span> = &#123;</span><br><span class="line">    <span class="comment">// <span class="doctag">TODO:</span> Handle changes of StorageLevel</span></span><br><span class="line">    <span class="keyword">if</span> (storageLevel != <span class="type">StorageLevel</span>.<span class="type">NONE</span> &amp;&amp; newLevel != storageLevel &amp;&amp; !allowOverride) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="type">SparkCoreErrors</span>.cannotChangeStorageLevelError()</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// If this is the first time this RDD is marked for persisting, register it</span></span><br><span class="line">    <span class="comment">// with the SparkContext for cleanups and accounting. Do this only once.</span></span><br><span class="line">    <span class="keyword">if</span> (storageLevel == <span class="type">StorageLevel</span>.<span class="type">NONE</span>) &#123;</span><br><span class="line">        sc.cleaner.foreach(_.registerRDDForCleanup(<span class="keyword">this</span>))</span><br><span class="line">        sc.persistRDD(<span class="keyword">this</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ä¿®æ”¹ rdd çš„å­˜å‚¨çº§åˆ«</span></span><br><span class="line">    storageLevel = newLevel</span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Register an RDD to be persisted in memory and/or disk storage</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">persistRDD</span></span>(rdd: <span class="type">RDD</span>[_]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// ç›¸å½“äºæ‰“ä¸€ä¸ªæ ‡è®°ï¼ŒçœŸæ­£è§¦å‘ rdd storage çš„åœ°æ–¹æ˜¯åœ¨ iterator çš„æ—¶å€™</span></span><br><span class="line">    persistentRdds(rdd.id) = rdd</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<blockquote>
<p>unpersist</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unpersist</span></span>(blocking: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="keyword">this</span>.<span class="keyword">type</span> = &#123;</span><br><span class="line">    logInfo(<span class="string">s&quot;Removing RDD <span class="subst">$id</span> from persistence list&quot;</span>)</span><br><span class="line">    sc.unpersistRDD(id, blocking)</span><br><span class="line">    storageLevel = <span class="type">StorageLevel</span>.<span class="type">NONE</span></span><br><span class="line">    <span class="keyword">this</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">unpersistRDD</span></span>(rddId: <span class="type">Int</span>, blocking: <span class="type">Boolean</span> = <span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="comment">// é€šçŸ¥blockManageråˆ æ‰å±äºè¯¥RDDçš„å…¨éƒ¨block</span></span><br><span class="line">    env.blockManager.master.removeRdd(rddId, blocking)</span><br><span class="line">    <span class="comment">// ä»mapä¸­ç§»æ‰å®ƒ</span></span><br><span class="line">    persistentRdds.remove(rddId)</span><br><span class="line">    listenerBus.post(<span class="type">SparkListenerUnpersistRDD</span>(rddId))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>è·å– persistent RDD çš„æ–¹æ³•ï¼š</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> rdds = sc.getPersistentRDDs</span><br><span class="line">rdds: scala.collection.<span class="type">Map</span>[<span class="type">Int</span>,org.apache.spark.rdd.<span class="type">RDD</span>[_]] = <span class="type">Map</span>(<span class="number">5</span> -&gt; <span class="type">ShuffledRDD</span>[<span class="number">5</span>] at partitionBy at &lt;console&gt;:<span class="number">28</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; rdds.foreach(println)</span><br><span class="line">(<span class="number">5</span>,<span class="type">ShuffledRDD</span>[<span class="number">5</span>] at partitionBy at &lt;console&gt;:<span class="number">28</span>)</span><br></pre></td></tr></table></figure>

<h5 id="iterator"><a href="#iterator" class="headerlink" title="iterator"></a>iterator</h5><p><a class="link" target="_blank" rel="noopener" href="https://www.runoob.com/scala/currying-functions.html">scala curring function<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link" target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/541508600">RDDç¼“å­˜çš„å®ç°é€»è¾‘åˆ†æ<i class="fas fa-external-link-alt"></i></a></p>
<p>iterator æ˜¯çœŸæ­£è§¦å‘å­˜å‚¨çš„åœ°æ–¹</p>
<ol>
<li><p><code>iterator</code></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">iterator</span></span>(split: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[<span class="type">T</span>] = &#123;</span><br><span class="line">    <span class="keyword">if</span> (storageLevel != <span class="type">StorageLevel</span>.<span class="type">NONE</span>) &#123;</span><br><span class="line">       	<span class="comment">// å¦‚æœå­˜å‚¨ç­‰çº§å­˜åœ¨çš„è¯ï¼Œè°ƒç”¨</span></span><br><span class="line">        getOrCompute(split, context)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// compute or è¯»å– checkpoint</span></span><br><span class="line">        computeOrReadCheckpoint(split, context)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</li>
<li><p><code>getOrComput</code> </p>
</li>
<li><ul>
<li>é€šè¿‡ cache æˆ–è€… checkpoint è¯»å–æ•°æ®</li>
<li>å¦åˆ™ computï¼Œç„¶å<strong>å­˜å‚¨</strong></li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">getOrCompute</span></span>(partition: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[<span class="type">T</span>] = &#123;</span><br><span class="line">    <span class="keyword">val</span> blockId = <span class="type">RDDBlockId</span>(id, partition.index)</span><br><span class="line">    <span class="keyword">var</span> readCachedBlock = <span class="literal">true</span></span><br><span class="line">    <span class="type">SparkEnv</span>.get.blockManager.getOrElseUpdate(blockId, storageLevel, elementClassTag, () =&gt; &#123;</span><br><span class="line">        <span class="comment">// å®šä¹‰äº†å¦‚æœ rdd æ²¡æœ‰å­˜å‚¨ï¼Œè®¡ç®—çš„è¿‡ç¨‹</span></span><br><span class="line">        readCachedBlock = <span class="literal">false</span></span><br><span class="line">        computeOrReadCheckpoint(partition, context)</span><br><span class="line">    &#125;) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="comment">// Block hit. é€šè¿‡ comput æˆ–è€… å­˜å‚¨ è·å–åˆ°æ•°æ®</span></span><br><span class="line">        <span class="keyword">case</span> <span class="type">Left</span>(blockResult) =&gt;</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment">// Need to compute the block. åªæœ‰ä¸å¤Ÿå­˜å‚¨çš„æ—¶å€™æ‰ä¼šå‡ºå‘è¿™ä¸ª comput</span></span><br><span class="line">        <span class="keyword">case</span> <span class="type">Right</span>(iter) =&gt;</span><br><span class="line">        <span class="keyword">new</span> <span class="type">InterruptibleIterator</span>(context, iter)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[spark] <span class="function"><span class="keyword">def</span> <span class="title">computeOrReadCheckpoint</span></span>(split: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[<span class="type">T</span>] =</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (isCheckpointedAndMaterialized) &#123;</span><br><span class="line">        <span class="comment">// å¦‚æœæœ‰ checkpointï¼ŒTODO</span></span><br><span class="line">        firstParent[<span class="type">T</span>].iterator(split, context)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// å¦åˆ™è®¡ç®—</span></span><br><span class="line">        compute(split, context)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/***</span></span><br><span class="line"><span class="comment">   * :: DeveloperApi ::</span></span><br><span class="line"><span class="comment">   * Implemented by subclasses to compute a given partition.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line"><span class="meta">@DeveloperApi</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(split: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[<span class="type">T</span>]</span><br></pre></td></tr></table></figure>


</li>
<li><p><code>getOrElseUpdate</code></p>
<ul>
<li>å‘½ä¸­ï¼Œè¯»å– storage</li>
<li>ä¸å‘½ä¸­ï¼Œcomput and storage</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getOrElseUpdate</span></span>[<span class="type">T</span>](</span><br><span class="line">    blockId: <span class="type">BlockId</span>,</span><br><span class="line">    level: <span class="type">StorageLevel</span>,</span><br><span class="line">    classTag: <span class="type">ClassTag</span>[<span class="type">T</span>],</span><br><span class="line">    makeIterator: () =&gt; <span class="type">Iterator</span>[<span class="type">T</span>]): <span class="type">Either</span>[<span class="type">BlockResult</span>, <span class="type">Iterator</span>[<span class="type">T</span>]] = &#123;</span><br><span class="line">    <span class="comment">// hit local or remote storage, retrun ans</span></span><br><span class="line">    get[<span class="type">T</span>](blockId)(classTag) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Some</span>(block) =&gt;</span><br><span class="line">        <span class="keyword">return</span> <span class="type">Left</span>(block)</span><br><span class="line">        <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        <span class="comment">// Need to compute the block.</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Initially we hold no locks on this block.</span></span><br><span class="line">    doPutIterator(blockId, makeIterator, level, classTag, keepReadLock = <span class="literal">true</span>) <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">        <span class="comment">// SUCCESS the block already existed or was successfully stored</span></span><br><span class="line">        <span class="type">Left</span>(blockResult)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Some</span>(iter) =&gt;</span><br><span class="line">        <span class="comment">// FAILED</span></span><br><span class="line">        <span class="comment">// The put failed, likely because the data was too large to fit in memory and could not be</span></span><br><span class="line">        <span class="comment">// dropped to disk. Therefore, we need to pass the input iterator back to the caller so</span></span><br><span class="line">        <span class="comment">// that they can decide what to do with the values (e.g. process them without caching).</span></span><br><span class="line">        <span class="type">Right</span>(iter)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</li>
<li><p><code>doPutIterator</code></p>
<ol>
<li>ä¼˜å…ˆä½¿ç”¨ memory<ol>
<li>å¯ä»¥åºåˆ—åŒ– <code>memoryStore.putIteratorAsBytes</code></li>
<li>ä¸èƒ½åºåˆ—åŒ– <code>memoryStore.putIteratorAsValues</code></li>
<li>ä½¿ç”¨ disk <code>diskStore.put</code></li>
</ol>
</li>
<li>ä½¿ç”¨ disk <code>diskStore.put</code></li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doPutIterator</span></span>[<span class="type">T</span>](</span><br><span class="line">    blockId: <span class="type">BlockId</span>,</span><br><span class="line">    iterator: () =&gt; <span class="type">Iterator</span>[<span class="type">T</span>],</span><br><span class="line">    level: <span class="type">StorageLevel</span>,</span><br><span class="line">    classTag: <span class="type">ClassTag</span>[<span class="type">T</span>],</span><br><span class="line">    tellMaster: <span class="type">Boolean</span> = <span class="literal">true</span>,</span><br><span class="line">    keepReadLock: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">Option</span>[<span class="type">PartiallyUnrolledIterator</span>[<span class="type">T</span>]] = &#123;</span><br><span class="line">    doPut(blockId, level, classTag, tellMaster = tellMaster, keepReadLock = keepReadLock) &#123; info =&gt;</span><br><span class="line">        <span class="keyword">val</span> startTimeNs = <span class="type">System</span>.nanoTime()</span><br><span class="line">        <span class="keyword">var</span> iteratorFromFailedMemoryStorePut: <span class="type">Option</span>[<span class="type">PartiallyUnrolledIterator</span>[<span class="type">T</span>]] = <span class="type">None</span></span><br><span class="line">        <span class="comment">// Size of the block in bytes</span></span><br><span class="line">        <span class="keyword">var</span> size = <span class="number">0</span>L</span><br><span class="line">        <span class="keyword">if</span> (level.useMemory) &#123;</span><br><span class="line">            <span class="comment">// ä¼˜å…ˆä½¿ç”¨å†…å­˜</span></span><br><span class="line">            <span class="comment">// Put it in memory first, even if it also has useDisk set to true;</span></span><br><span class="line">            <span class="comment">// We will drop it to disk later if the memory store can&#x27;t hold it.</span></span><br><span class="line">            <span class="keyword">if</span> (level.deserialized) &#123;</span><br><span class="line">                <span class="comment">// ä¸èƒ½åºåˆ—åŒ–ï¼Œiterator() éœ€è¦å¯åŠ¨ executor å…ˆè¿›è¡Œè®¡ç®—ï¼Œå¾—åˆ° resï¼Œå­˜å‚¨</span></span><br><span class="line">                memoryStore.putIteratorAsValues(blockId, iterator(), level.memoryMode, classTag) <span class="keyword">match</span> &#123;</span><br><span class="line">                    <span class="keyword">case</span> <span class="type">Right</span>(s) =&gt;</span><br><span class="line">                    size = s</span><br><span class="line">                    <span class="keyword">case</span> <span class="type">Left</span>(iter) =&gt;</span><br><span class="line">                    <span class="comment">// Not enough space to unroll this block; drop to disk if applicable</span></span><br><span class="line">                    <span class="keyword">if</span> (level.useDisk) &#123;</span><br><span class="line">                        <span class="comment">// ä½¿ç”¨ disk å­˜å‚¨</span></span><br><span class="line">                        diskStore.put(blockId) &#123; channel =&gt;</span><br><span class="line">                            <span class="keyword">val</span> out = <span class="type">Channels</span>.newOutputStream(channel)</span><br><span class="line">                            serializerManager.dataSerializeStream(blockId, out, iter)(classTag)</span><br><span class="line">                        &#125;</span><br><span class="line">                        size = diskStore.getSize(blockId)</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        iteratorFromFailedMemoryStorePut = <span class="type">Some</span>(iter)</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123; <span class="comment">// !level.deserialized</span></span><br><span class="line">                <span class="comment">// å¯ä»¥åºåˆ—åŒ–ï¼Œiterator() éœ€è¦å¯åŠ¨ executor å…ˆè¿›è¡Œè®¡ç®—ï¼Œå¾—åˆ° resï¼Œå­˜å‚¨</span></span><br><span class="line">                memoryStore.putIteratorAsBytes(blockId, iterator(), classTag, level.memoryMode) <span class="keyword">match</span> &#123;</span><br><span class="line">                    <span class="keyword">case</span> <span class="type">Right</span>(s) =&gt;</span><br><span class="line">                    size = s</span><br><span class="line">                    <span class="keyword">case</span> <span class="type">Left</span>(partiallySerializedValues) =&gt;</span><br><span class="line">                    <span class="comment">// Not enough space to unroll this block; drop to disk if applicable</span></span><br><span class="line">                    <span class="keyword">if</span> (level.useDisk) &#123;</span><br><span class="line">                        <span class="comment">// ä½¿ç”¨ disk</span></span><br><span class="line">                        logWarning(<span class="string">s&quot;Persisting block <span class="subst">$blockId</span> to disk instead.&quot;</span>)</span><br><span class="line">                        diskStore.put(blockId) &#123; channel =&gt;</span><br><span class="line">                            <span class="keyword">val</span> out = <span class="type">Channels</span>.newOutputStream(channel)</span><br><span class="line">                            partiallySerializedValues.finishWritingToStream(out)</span><br><span class="line">                        &#125;</span><br><span class="line">                        size = diskStore.getSize(blockId)</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        iteratorFromFailedMemoryStorePut = <span class="type">Some</span>(partiallySerializedValues.valuesIterator)</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (level.useDisk) &#123;</span><br><span class="line">            <span class="comment">// ä½¿ç”¨ disk</span></span><br><span class="line">            diskStore.put(blockId) &#123; channel =&gt;</span><br><span class="line">                <span class="keyword">val</span> out = <span class="type">Channels</span>.newOutputStream(channel)</span><br><span class="line">                serializerManager.dataSerializeStream(blockId, out, iterator())(classTag)</span><br><span class="line">            &#125;</span><br><span class="line">            size = diskStore.getSize(blockId)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>memory åº•å±‚å­˜å‚¨çš„æœ¬è´¨æ˜¯è°ƒç”¨ <code>putIterator</code></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">putIterator</span></span>[<span class="type">T</span>](</span><br><span class="line">    blockId: <span class="type">BlockId</span>,</span><br><span class="line">    values: <span class="type">Iterator</span>[<span class="type">T</span>],</span><br><span class="line">    classTag: <span class="type">ClassTag</span>[<span class="type">T</span>],</span><br><span class="line">    memoryMode: <span class="type">MemoryMode</span>,</span><br><span class="line">    valuesHolder: <span class="type">ValuesHolder</span>[<span class="type">T</span>]): <span class="type">Either</span>[<span class="type">Long</span>, <span class="type">Long</span>] = &#123;</span><br><span class="line">    require(!contains(blockId), <span class="string">s&quot;Block <span class="subst">$blockId</span> is already present in the MemoryStore&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Number of elements unrolled so far ï½œ å½“å‰éœ€è¦å­˜å‚¨çš„ elem æ•°é‡</span></span><br><span class="line">    <span class="keyword">var</span> elementsUnrolled = <span class="number">0</span></span><br><span class="line">    <span class="comment">// Whether there is still enough memory for us to continue unrolling this block ï½œ æ˜¯å¦éœ€è¦ç»§ç»­ rolling</span></span><br><span class="line">    <span class="keyword">var</span> keepUnrolling = <span class="literal">true</span></span><br><span class="line">    <span class="comment">// Initial per-task memory to request for unrolling blocks (bytes). ï½œ åˆå§‹åŒ–ç”³è¯· memo çš„å¤§å° default 1M</span></span><br><span class="line">    <span class="keyword">val</span> initialMemoryThreshold = unrollMemoryThreshold</span><br><span class="line">    <span class="comment">// How often to check whether we need to request more memory ï½œ unrolling å¤šå°‘ä¸ª elem è¿›è¡Œä¸€æ¬¡ memo å¤§å°æ£€æŸ¥ default 16</span></span><br><span class="line">    <span class="keyword">val</span> memoryCheckPeriod = conf.get(<span class="type">UNROLL_MEMORY_CHECK_PERIOD</span>)</span><br><span class="line">    <span class="comment">// Memory currently reserved by this task for this particular unrolling operation ï½œ å½“å‰å ç”¨ memo çš„å¤§å°</span></span><br><span class="line">    <span class="keyword">var</span> memoryThreshold = initialMemoryThreshold</span><br><span class="line">    <span class="comment">// Memory to request as a multiple of current vector size ï½œ vector æ‰©å®¹çš„ frac default 1.5</span></span><br><span class="line">    <span class="keyword">val</span> memoryGrowthFactor = conf.get(<span class="type">UNROLL_MEMORY_GROWTH_FACTOR</span>)</span><br><span class="line">    <span class="comment">// Keep track of unroll memory used by this particular block / putIterator() operation</span></span><br><span class="line">    <span class="keyword">var</span> unrollMemoryUsedByThisBlock = <span class="number">0</span>L</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Request enough memory to begin unrolling ï½œ ç”³è¯·åˆå§‹åŒ– memo</span></span><br><span class="line">    keepUnrolling =</span><br><span class="line">    reserveUnrollMemoryForThisTask(blockId, initialMemoryThreshold, memoryMode)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!keepUnrolling) &#123;</span><br><span class="line">        logWarning(<span class="string">s&quot;Failed to reserve initial memory threshold of &quot;</span> +</span><br><span class="line">                   <span class="string">s&quot;<span class="subst">$&#123;Utils.bytesToString(initialMemoryThreshold)&#125;</span> for computing block <span class="subst">$blockId</span> in memory.&quot;</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        unrollMemoryUsedByThisBlock += initialMemoryThreshold</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Unroll this block safely, checking whether we have exceeded our threshold periodically</span></span><br><span class="line">    <span class="keyword">while</span> (values.hasNext &amp;&amp; keepUnrolling) &#123;</span><br><span class="line">        <span class="comment">// å°†å½“å‰å…ƒç´ åŠ å…¥ vector</span></span><br><span class="line">        valuesHolder.storeValue(values.next())</span><br><span class="line">        <span class="comment">// å¦‚æœåˆ°äº†ä¸€ä¸ª periodï¼Œåˆ™è¿›è¡Œä¸€ä¸ª memo å®¹é‡æ£€æŸ¥</span></span><br><span class="line">        <span class="keyword">if</span> (elementsUnrolled % memoryCheckPeriod == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// ä¼°ç®—å½“å‰ vector çš„å­˜å‚¨å®¹é‡</span></span><br><span class="line">            <span class="keyword">val</span> currentSize = valuesHolder.estimatedSize()</span><br><span class="line">            <span class="comment">// If our vector&#x27;s size has exceeded the threshold, request more memory ï½œ è¶…è¿‡å®¹é‡éœ€è¦ memo æ‰©å®¹</span></span><br><span class="line">            <span class="keyword">if</span> (currentSize &gt;= memoryThreshold) &#123;</span><br><span class="line">                <span class="keyword">val</span> amountToRequest = (currentSize * memoryGrowthFactor - memoryThreshold).toLong</span><br><span class="line">                keepUnrolling =</span><br><span class="line">                reserveUnrollMemoryForThisTask(blockId, amountToRequest, memoryMode)</span><br><span class="line">                <span class="keyword">if</span> (keepUnrolling) &#123;</span><br><span class="line">                    unrollMemoryUsedByThisBlock += amountToRequest</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// New threshold is currentSize * memoryGrowthFactor</span></span><br><span class="line">                memoryThreshold += amountToRequest</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        elementsUnrolled += <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Make sure that we have enough memory to store the block. By this point, it is possible that</span></span><br><span class="line">    <span class="comment">// the block&#x27;s actual memory usage has exceeded the unroll memory by a small amount, so we</span></span><br><span class="line">    <span class="comment">// perform one final call to attempt to allocate additional memory if necessary.</span></span><br><span class="line">    <span class="keyword">if</span> (keepUnrolling) &#123;</span><br><span class="line">        <span class="keyword">val</span> entry = entryBuilder.build()</span><br><span class="line">        <span class="comment">// Synchronize so that transfer is atomic ï½œ è¿›è¡Œä¸€ä¸ª memo çš„å­˜å‚¨</span></span><br><span class="line">        entries.synchronized &#123;</span><br><span class="line">            entries.put(blockId, entry)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        logInfo(<span class="string">&quot;Block %s stored as values in memory (estimated size %s, free %s)&quot;</span>.format(blockId,</span><br><span class="line">                                                                                          <span class="type">Utils</span>.bytesToString(entry.size), 																						      <span class="type">Utils</span>.bytesToString(maxMemory - blocksMemoryUsed)))</span><br><span class="line">        <span class="type">Right</span>(entry.size)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// We ran out of space while unrolling the values for this block</span></span><br><span class="line">        logUnrollFailureMessage(blockId, valuesHolder.estimatedSize())</span><br><span class="line">        <span class="type">Left</span>(unrollMemoryUsedByThisBlock)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h5><p>cache å’Œ persist å°†æ•°æ®æŒä¹…åŒ–åˆ° memory æˆ–è€… diskï¼Œè€Œä¸”ä¿å­˜äº†è¡€ç¼˜å…³ç³»ã€‚å¦‚æœå‡ºç° node crash çš„æƒ…å†µè¿˜æ˜¯å¯ä»¥é‡æ–°è®¡ç®—çš„ã€‚</p>
<p>chechpoint æ˜¯ç›´æ¥å°†æ•°æ®æŒä¹…åŒ–åˆ° hdfs ä¸­ï¼Œå› ä¸º hdfs çš„é«˜å¯é æ€§ï¼Œæ‰€ä»¥æ‰€ä»¥é˜¶æ®µä¹‹å‰çš„è¡€ç¼˜å…³ç³»ã€‚</p>
<blockquote>
<p>checkpoint saves the RDD to an HDFS file and actually forgets the lineage completely. This is allows long lineages to be truncated and the data to be saved reliably in HDFS</p>
</blockquote>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// è®¾ç½® checkpoint çš„ä¿å­˜è·¯å¾„</span></span><br><span class="line">sc.setCheckpointDir(<span class="string">&quot;ckp&quot;</span>)</span><br></pre></td></tr></table></figure>



<h3 id="ç¯å¢ƒæ­å»º"><a href="#ç¯å¢ƒæ­å»º" class="headerlink" title="ç¯å¢ƒæ­å»º"></a>ç¯å¢ƒæ­å»º</h3><p>åˆ†æ <code>spark-shubmit</code> çš„æ‰§è¡Œæµç¨‹ï¼š</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash">SPARK_HOME/bin/spark-submit \</span></span><br><span class="line"><span class="language-bash">--class <span class="string">&quot;SimpleApp&quot;</span> \</span></span><br><span class="line"><span class="language-bash">--master <span class="built_in">local</span> \ <span class="comment"># 5.3 æ„å»º app å¯¹è±¡ ï¼ˆSTANDALONE_CLUSTER_SUBMIT_CLASSï¼‰</span></span></span><br><span class="line">./target/scala-2.13/simple-app_2.13-1.0.jar</span><br></pre></td></tr></table></figure>


<ol>
<li><p>è°ƒç”¨ spark-submit è„šæœ¬ä¼šæ‰§è¡Œ <code>java org.apache.deploy.SparkSubmit</code> å¯¹è±¡ã€‚</p>
</li>
<li><p>åˆ›å»º SparkSubmit å¯¹è±¡è°ƒç”¨ doSubmit æ–¹æ³•</p>
</li>
<li><p>è§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œé»˜è®¤ <code>action</code> ä¸º <code>SUBMIT</code>, <code>action = Option(action).getOrElse(SUBMIT)</code></p>
</li>
<li><p>è°ƒç”¨ submit æ–¹æ³•ï¼Œ&#x3D;&gt; è°ƒç”¨ runMain æ–¹æ³•ã€‚</p>
</li>
<li><p>runMain æ–¹æ³•</p>
</li>
<li><p>è§£æå‘½ä»¤è¡Œå‚æ•° &#x3D;&gt; master &#x3D;&#x3D; â€˜localâ€™ &#x3D;&gt; LOCAL</p>
</li>
<li><p>è·å– childMainClass</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[deploy] <span class="keyword">val</span> <span class="type">YARN_CLUSTER_SUBMIT_CLASS</span> =</span><br><span class="line"><span class="string">&quot;org.apache.spark.deploy.yarn.YarnClusterApplication&quot;</span></span><br><span class="line"><span class="keyword">private</span>[deploy] <span class="keyword">val</span> <span class="type">REST_CLUSTER_SUBMIT_CLASS</span> = classOf[<span class="type">RestSubmissionClientApp</span>].getName()</span><br><span class="line"><span class="keyword">private</span>[deploy] <span class="keyword">val</span> <span class="type">STANDALONE_CLUSTER_SUBMIT_CLASS</span> = classOf[<span class="type">ClientApp</span>].getName()</span><br><span class="line"><span class="keyword">private</span>[deploy] <span class="keyword">val</span> <span class="type">KUBERNETES_CLUSTER_SUBMIT_CLASS</span> =</span><br><span class="line"><span class="string">&quot;org.apache.spark.deploy.k8s.submit.KubernetesClientApplication&quot;</span></span><br></pre></td></tr></table></figure></li>
<li><p>é€šè¿‡ mainClass åå°„åˆ›å»º appï¼Œï¼ˆåå°„ï¼šé€šè¿‡ classname åŠ¨æ€åŠ è½½å’Œæ„é€ å¯¹è±¡ï¼‰ï¼Œå¹¶è°ƒç”¨ start æ–¹æ³•ï¼Œå¼€å§‹è¿è¡Œç”¨æˆ·çš„ä»£ç </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mainClass = <span class="type">Utils</span>.classForName(childMainClass)</span><br><span class="line"><span class="keyword">val</span> app: <span class="type">SparkApplication</span> = <span class="keyword">if</span> (classOf[<span class="type">SparkApplication</span>].isAssignableFrom(mainClass)) &#123;</span><br><span class="line">    mainClass.getConstructor().newInstance().asInstanceOf[<span class="type">SparkApplication</span>]</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">JavaMainApplication</span>(mainClass)</span><br><span class="line">&#125;</span><br><span class="line">app.start(childArgs.toArray, sparkConf)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Driver é¦–å…ˆåˆ›å»º sparkContext å¯¹è±¡çš„åˆ›å»º</p>
</li>
<li><p>å½“ sparkContext åˆå§‹åŒ–ä¹‹åï¼Œä¼šç­‰å¾… system èµ„æºåˆ›å»ºå®Œæˆï¼Œè°ƒç”¨ Hook å‡½æ•°ç­‰å¾…ã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Post init</span></span><br><span class="line">_taskScheduler.postStartHook()</span><br><span class="line"></span><br><span class="line"><span class="comment">// Invoked after system has successfully initialized (typically in spark context).</span></span><br><span class="line"><span class="comment">// Yarn uses this to bootstrap allocation of resources based on preferred locations,</span></span><br><span class="line"><span class="comment">// wait for executor registrations, etc.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">postStartHook</span></span>(): <span class="type">Unit</span> = &#123; &#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>åˆ›å»ºå®Œæˆä¹‹åï¼Œç»§ç»­æ‰§è¡Œç”¨æˆ·çš„ä»£ç ï¼Œè¯»å†™æ–‡ä»¶æˆ–è€…æ“ä½œ rddã€‚</p>
</li>
</ol>
<p><img src="https://img-blog.csdn.net/20180813202155856?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3l1bWluZ3podTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="spark-process"></p>
<p><a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/yumingzhu1/article/details/81636408?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-81636408-blog-81703467.pc_relevant_recovery_v2&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-81636408-blog-81703467.pc_relevant_recovery_v2&utm_relevant_index=3">standalone process<i class="fas fa-external-link-alt"></i></a></p>
<h3 id="sparkcontext"><a href="#sparkcontext" class="headerlink" title="sparkcontext"></a>sparkcontext</h3><h4 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h4><p>åœ¨Sparkæ¡†æ¶ä¸­ï¼Œåº”ç”¨ç¨‹åºçš„æäº¤ç¦»ä¸å¼€<code>Spark Driver</code>ï¼Œè€Œ<code>Spark Driver</code>çš„åˆå§‹åŒ–å§‹ç»ˆå›´ç»•<code>SparkContext</code>çš„åˆå§‹åŒ–ï¼Œå¯ä»¥è¯´<code>SparkContext</code>æ˜¯<code>Spark</code>ç¨‹åºçš„å‘åŠ¨æœºå¼•æ“ï¼Œæœ‰äº†å®ƒç¨‹åºæ‰èƒ½è·‘èµ·æ¥ï¼Œåœ¨<code>spark-core</code>ä¸­ï¼Œ<code>SparkContext</code>é‡ä¸­ä¹‹é‡ï¼Œå®ƒæä¾›äº†å¾ˆå¤šèƒ½åŠ›ï¼Œæ¯”å¦‚ç”Ÿæˆ<code>RDD</code>ï¼Œæ¯”å¦‚ç”Ÿæˆå¹¿æ’­å˜é‡ç­‰ï¼Œæ‰€ä»¥å­¦ä¹ <code>SparkContext</code>çš„ç»„ä»¶å’Œå¯åŠ¨æµç¨‹æœ‰åŠ©äºå‰–ææ•´ä¸ª<code>Spark</code>å†…æ ¸çš„æ¶æ„ã€‚</p>
<h4 id="SparkContextç»„ä»¶æ¦‚è§ˆ"><a href="#SparkContextç»„ä»¶æ¦‚è§ˆ" class="headerlink" title="SparkContextç»„ä»¶æ¦‚è§ˆ"></a>SparkContextç»„ä»¶æ¦‚è§ˆ</h4><p>åœ¨SparkContextä¸­åŒ…å«äº†æ•´ä¸ªæ¡†æ¶ä¸­å¾ˆé‡è¦çš„å‡ éƒ¨åˆ†ï¼š</p>
<ul>
<li>SparkEnvï¼šSparkçš„è¿è¡Œç¯å¢ƒï¼ŒExecutorä¼šä¾èµ–å®ƒå»æ‰§è¡Œåˆ†é…çš„taskï¼Œä¸å…‰Executorä¸­æœ‰ï¼ŒåŒæ—¶ä¸ºäº†ä¿è¯æœ¬åœ°æ¨¡å¼ä»»åŠ¡ä¹Ÿèƒ½è·‘èµ·æ¥ï¼ŒDriverä¸­ä¹Ÿæœ‰</li>
<li>SparkUIï¼šSparkä½œä¸šçš„ç›‘æ§é¡µé¢ï¼Œåº•å±‚å¹¶æ²¡æœ‰é‡‡ç”¨å‰ç«¯æŠ€æœ¯ï¼Œçº¯åç«¯å®ç°ï¼Œç”¨ä»¥å¯¹å½“å‰SparkJobçš„ç›‘æ§å’Œè°ƒä¼˜ï¼Œå¯ä»¥ä»é¡µé¢è§‚å¯Ÿåˆ°ç›®å‰çš„Executorçš„jvmä¿¡æ¯ï¼Œæ¯ä¸ªjobçš„stageåˆ’åˆ†å’Œtaskåˆ’åˆ†ï¼ŒåŒæ—¶è¿˜å¯ä»¥è§‚å¯Ÿåˆ°æ¯ä¸ªtaskå¤„ç†çš„æ•°æ®ï¼Œç”¨ä»¥å‘ç°æ•°æ®æ˜¯å¦å€¾æ–œ</li>
<li>DAGSchedulerï¼šDAGè°ƒåº¦å™¨ï¼Œæ˜¯SparkJobè°ƒåº¦ç³»ç»Ÿçš„é‡è¦ç»„ä»¶ä¹‹ä¸€ï¼Œè´Ÿè´£åˆ›å»ºjobï¼Œæ ¹æ®RDDä¾èµ–æƒ…å†µåˆ’åˆ†stageï¼Œæäº¤stageï¼Œå°†ä½œä¸šåˆ’åˆ†æˆä¸€ä¸ªæœ‰å‘æ— ç¯å›¾</li>
<li>TaskSchedulerï¼šä»»åŠ¡è°ƒåº¦å™¨ï¼Œæ˜¯SparkJobè°ƒåº¦ç³»ç»Ÿçš„é‡è¦ç»„ä»¶ä¹‹ä¸€ï¼Œè´Ÿè´£æŒ‰ç…§è°ƒåº¦ç®—æ³•å°†DAGScheduleråˆ›å»ºçš„taskåˆ†å‘è‡³Executorï¼ŒDAGScheduleræ˜¯å®ƒçš„å‰ç½®è°ƒåº¦</li>
<li>SparkStatusTrackerï¼šæä¾›å¯¹ä½œä¸šã€Stageçš„ç›‘æ§</li>
<li>ConsoleProcessBarï¼šåˆ©ç”¨SparkStatusTrackeræä¾›ç›‘æ§ä¿¡æ¯ï¼Œå°†ä»»åŠ¡è¿›åº¦ä»¥æ—¥å¿—çš„å½¢å¼æ‰“å°åˆ°ç»ˆç«¯ä¸­</li>
<li>HearbeatReceiverï¼šå¿ƒè·³æ¥æ”¶å™¨ï¼Œæ‰€æœ‰Executoréƒ½ä¼šå®šæœŸå‘å®ƒå‘é€å¿ƒè·³ä¿¡æ¯ï¼Œç”¨ä»¥ç»Ÿè®¡å­˜æ´»çš„Executorï¼Œæ­¤ä¿¡æ¯ä¼šä¸€ç›´åŒæ­¥ç»™TaskSchedulerï¼Œç”¨ä»¥ä¿è¯TaskSchedulerå»åˆ†å‘taskçš„æ—¶å€™ä¼šæŒ‘é€‰åˆé€‚çš„Executor</li>
<li>ContextCleanerï¼šä¸Šä¸‹æ–‡æ¸…ç†å™¨ï¼Œç”¨å¼‚æ­¥çš„æ–¹å¼å»æ¸…ç†é‚£äº›è¶…å‡ºåº”ç”¨ä½œç”¨åŸŸèŒƒå›´çš„RDDã€ShuffleDependencyå’ŒBroadcast</li>
<li>LiveListenerBusï¼šSparkContextä¸­çš„äº‹ä»¶æ€»çº¿ï¼Œå¯ä»¥æ¥æ”¶å„ä¸ªç»„ä»¶çš„äº‹ä»¶ï¼Œå¹¶ä¸”é€šè¿‡å¼‚æ­¥çš„æ–¹å¼å¯¹äº‹ä»¶è¿›è¡ŒåŒ¹é…å¹¶è°ƒç”¨ä¸åŒçš„å›è°ƒæ–¹æ³•</li>
<li>ShutdownHookManagerï¼šå…³é—­æ—¶çš„é’©å­ç®¡ç†å™¨ï¼Œç”¨ä»¥åšä¸€äº›æ¸…ç†å·¥ä½œï¼Œæ¯”å¦‚èµ„æºé‡Šæ”¾ç­‰</li>
<li>AppStatusStoreï¼šå­˜å‚¨ApplicationçŠ¶æ€æ•°æ®ï¼Œåœ¨2.3.0ä¹‹åçš„ç‰ˆæœ¬å¼•å…¥</li>
<li>EventLoggingListenerï¼ˆå¯é€‰ï¼‰ï¼šå°†äº‹ä»¶æŒä¹…åŒ–åˆ°å­˜å‚¨çš„ç›‘å¬å™¨ï¼Œé€šè¿‡<code>spark.eventLog.enabled</code> è¿›è¡Œæ§åˆ¶</li>
<li>ExecutorAllocationManagerï¼ˆå¯é€‰ï¼‰ï¼šExecutoråŠ¨æ€åˆ†é…ç®¡ç†å™¨ï¼Œæ ¹æ®å·¥ä½œè´Ÿè½½çŠ¶æ€åŠ¨æ€è°ƒæ•´Executorçš„æ•°é‡ï¼Œé€šè¿‡å±æ€§<code>spark.dynamicAllocation.enabled</code> å’Œ<code>spark.dynamicAllocation.testing</code> è¿›è¡Œæ§åˆ¶</li>
</ul>
<h3 id="ä»»åŠ¡è°ƒåº¦"><a href="#ä»»åŠ¡è°ƒåº¦" class="headerlink" title="ä»»åŠ¡è°ƒåº¦"></a>ä»»åŠ¡è°ƒåº¦</h3><p><img src="https://oss-emcsprod-public.modb.pro/wechatSpider/modb_20220704_70bbb896-fb8b-11ec-a026-fa163eb4f6be.png" alt="process"></p>
<h4 id="Action-è§¦å‘-Job-submit-åˆ°-DAGScheduler-eventProcessLoop"><a href="#Action-è§¦å‘-Job-submit-åˆ°-DAGScheduler-eventProcessLoop" class="headerlink" title="Action è§¦å‘ Job submit åˆ° DAGScheduler eventProcessLoop"></a>Action è§¦å‘ Job submit åˆ° DAGScheduler eventProcessLoop</h4><ol>
<li><p>ä½¿ç”¨ RDD çš„ collect æ–¹æ³•å¯ä»¥å‡ºå‘ actionï¼Œå¯¼è‡´ä½œä¸šæäº¤ã€‚</p>
<p>runJob with param <code>rdd</code> <code>func</code> <code>partitions</code></p>
</li>
</ol>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collect</span></span>(): <span class="type">Array</span>[<span class="type">T</span>] = withScope &#123;</span><br><span class="line">    <span class="keyword">val</span> results = sc.runJob(<span class="keyword">this</span>, (iter: <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; iter.toArray)</span><br><span class="line">    <span class="type">Array</span>.concat(results: _*)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<ol start="2">
<li><p>é€šè¿‡ <code>dagScheduler</code> è¿›è¡Œä½œä¸šæäº¤</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)</span><br></pre></td></tr></table></figure>

<p>ç„¶åé€šè¿‡ <code>submitJob</code> å°†ä½œä¸šæäº¤ã€‚å¹¶ç­‰å¾…ä½œä¸šè¿”å›ã€‚</p>
</li>
<li><p><code>submitJob</code> å°† Job åŠ å…¥åˆ° dagScheduler çš„äº‹ä»¶å¾ªç¯ä¸­ï¼Œç­‰å¾… Job è¢«è°ƒåº¦ã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="keyword">val</span> eventProcessLoop = <span class="keyword">new</span> <span class="type">DAGSchedulerEventProcessLoop</span>(<span class="keyword">this</span>)</span><br><span class="line"></span><br><span class="line">eventProcessLoop.post(<span class="type">JobSubmitted</span>(</span><br><span class="line">      jobId, rdd, func2, partitions.toArray, callSite, waiter,</span><br><span class="line">      <span class="type">Utils</span>.cloneProperties(properties)))</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="DAGScheduler-å¯¹-Job-è¿›è¡Œ-Stage-åˆ’åˆ†ï¼Œå¹¶ä¸”æäº¤-Task-åˆ°-TaskScheduler"><a href="#DAGScheduler-å¯¹-Job-è¿›è¡Œ-Stage-åˆ’åˆ†ï¼Œå¹¶ä¸”æäº¤-Task-åˆ°-TaskScheduler" class="headerlink" title="DAGScheduler å¯¹ Job è¿›è¡Œ Stage åˆ’åˆ†ï¼Œå¹¶ä¸”æäº¤ Task åˆ° TaskScheduler"></a>DAGScheduler å¯¹ Job è¿›è¡Œ Stage åˆ’åˆ†ï¼Œå¹¶ä¸”æäº¤ Task åˆ° TaskScheduler</h4><ol>
<li><p>dagScheduler eventProcessLoop é€šè¿‡ onReceive æ–¹æ³•å¤„ç†äº‹ä»¶ã€‚ç„¶åè°ƒç”¨ <code>dagScheduler.handleJobSubmitted</code> æ¥å¤„ç†ä¹‹å‰ Job çš„æäº¤ã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The main event loop of the DAG scheduler.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onReceive</span></span>(event: <span class="type">DAGSchedulerEvent</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> timerContext = timer.time()</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        doOnReceive(event)</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        timerContext.stop()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doOnReceive</span></span>(event: <span class="type">DAGSchedulerEvent</span>): <span class="type">Unit</span> = event <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">JobSubmitted</span>(jobId, rdd, func, partitions, callSite, listener, properties) =&gt;</span><br><span class="line">    dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> <span class="type">MapStageSubmitted</span>(jobId, dependency, callSite, listener, properties) =&gt;</span><br><span class="line">    dagScheduler.handleMapStageSubmitted(jobId, dependency, callSite, listener, properties)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


</li>
<li><p>åœ¨ <code>handleJobSubmitted</code> ä¸­ï¼Œä¼šè¿›è¡Œ stage çš„åˆ’åˆ†ï¼Œå¹¶ä¸”å°†æ‰€æœ‰çš„ stage åŒ…æ‹¬ parent stage and ancient stage å…¨éƒ¨æäº¤ï¼Œé€šè¿‡ DFS çš„æ–¹å¼</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. è°ƒç”¨åˆ›å»º ResultStage çš„æ–¹æ³•</span></span><br><span class="line">finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1.1 é¦–å…ˆä¼šè·å– trigger action rdd çš„æ‰€æœ‰ shuffleDepsï¼Œç„¶åä½¿ç”¨ shuffleDeps åˆ›å»ºå½“å‰ rdd çš„æ‰€æœ‰ parentï¼ˆä¸åŒ…æ‹¬ parent çš„ parentï¼‰ï¼Œæœ€ååˆ›å»º resultStage</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// è·å– shuffleDeps çš„æ–¹æ³•å°±æ˜¯ BFS</span></span><br><span class="line"><span class="keyword">val</span> (shuffleDeps, resourceProfiles) = getShuffleDependenciesAndResourceProfiles(rdd)</span><br><span class="line"><span class="keyword">val</span> parents = getOrCreateParentStages(shuffleDeps, jobId)</span><br><span class="line"><span class="keyword">val</span> stage = <span class="keyword">new</span> <span class="type">ResultStage</span>(id, rdd, func, partitions, parents, jobId,</span><br><span class="line">                            callSite, resourceProfile.id)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. æäº¤ stageï¼Œè¿™é‡Œçš„ finalStage å°±æ˜¯ resultStage</span></span><br><span class="line">submitStage(finalStage)</span><br></pre></td></tr></table></figure>



<p><code>getShuffleDependenciesAndResourceProfiles</code> æ–¹æ³•ï¼ˆBFSï¼‰ï¼š</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">getShuffleDependenciesAndResourceProfiles</span></span>(</span><br><span class="line">    rdd: <span class="type">RDD</span>[_]): (<span class="type">HashSet</span>[<span class="type">ShuffleDependency</span>[_, _, _]], <span class="type">HashSet</span>[<span class="type">ResourceProfile</span>]) = &#123;</span><br><span class="line">    <span class="comment">// rdd å…¨éƒ¨ parent åˆ—è¡¨</span></span><br><span class="line">    <span class="keyword">val</span> parents = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">ShuffleDependency</span>[_, _, _]]</span><br><span class="line">	<span class="comment">// è®°å¿†åŒ–</span></span><br><span class="line">    <span class="keyword">val</span> visited = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">RDD</span>[_]]</span><br><span class="line">    <span class="comment">// queue</span></span><br><span class="line">    <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">RDD</span>[_]]</span><br><span class="line">    waitingForVisit += rdd</span><br><span class="line">    <span class="keyword">while</span> (waitingForVisit.nonEmpty) &#123;</span><br><span class="line">        <span class="keyword">val</span> toVisit = waitingForVisit.remove(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> (!visited(toVisit)) &#123;</span><br><span class="line">            visited += toVisit</span><br><span class="line">            <span class="type">Option</span>(toVisit.getResourceProfile).foreach(resourceProfiles += _)</span><br><span class="line">            toVisit.dependencies.foreach &#123;</span><br><span class="line">                <span class="comment">// å¦‚æœæ˜¯ shuffleDeps å°†å®ƒåŠ å…¥ parent ä¸­ï¼Œstage ä¼šä»è¿™ä¸ªåœ°æ–¹æ–­å¼€</span></span><br><span class="line">                <span class="keyword">case</span> shuffleDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</span><br><span class="line">                parents += shuffleDep</span><br><span class="line">                <span class="comment">// å¦‚æœæ˜¯ narrowDepsï¼Œåˆ™å°†å®ƒåŠ å…¥ queue è¿›è¡Œ BFS</span></span><br><span class="line">                <span class="keyword">case</span> dependency =&gt;</span><br><span class="line">                waitingForVisit.prepend(dependency.rdd)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    (parents, resourceProfiles)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Submits stage, but first recursively submits any missing parents. */</span></span><br><span class="line"><span class="comment">// æäº¤ resultStage å’Œ shuffleMapStage recursively é€šè¿‡ submitStage</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitStage</span></span>(stage: <span class="type">Stage</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> jobId = activeJobForStage(stage)</span><br><span class="line">    <span class="keyword">if</span> (jobId.isDefined) &#123;</span><br><span class="line">        logDebug(<span class="string">s&quot;submitStage(<span class="subst">$stage</span> (name=<span class="subst">$&#123;stage.name&#125;</span>;&quot;</span> +</span><br><span class="line">                 <span class="string">s&quot;jobs=<span class="subst">$&#123;stage.jobIds.toSeq.sorted.mkString(&quot;,&quot;)&#125;</span>))&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123;</span><br><span class="line">            <span class="keyword">val</span> missing = getMissingParentStages(stage).sortBy(_.id)</span><br><span class="line">            logDebug(<span class="string">&quot;missing: &quot;</span> + missing)</span><br><span class="line">            <span class="keyword">if</span> (missing.isEmpty) &#123;</span><br><span class="line">                logInfo(<span class="string">&quot;Submitting &quot;</span> + stage + <span class="string">&quot; (&quot;</span> + stage.rdd + <span class="string">&quot;), which has no missing parents&quot;</span>)</span><br><span class="line">                <span class="comment">// å¦‚æœæ²¡æœ‰ missing çš„ parent stage å°±ä¼šæäº¤å½“å‰é˜¶æ®µ</span></span><br><span class="line">                submitMissingTasks(stage, jobId.get)</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">for</span> (parent &lt;- missing) &#123;</span><br><span class="line">                    <span class="comment">// ä¸ç„¶å…ˆæäº¤ parent stage</span></span><br><span class="line">                    submitStage(parent)</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// æœ€åå°†å½“å‰ stage åŠ å…¥åˆ° waitingStage ä¸­</span></span><br><span class="line">                waitingStages += stage</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        abortStage(stage, <span class="string">&quot;No active job for stage &quot;</span> + stage.id, <span class="type">None</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// submitMissingTasks ä¸­ä¼šæ ¹æ®å½“å‰ stage ç±»å‹ï¼Œç„¶åé€šè¿‡ partitionï¼Œrdd åˆ›å»ºå¯¹åº”çš„ Tasksã€‚rdd ä¸­æœ‰å¤šå°‘ä¸ªåˆ†åŒºå°±ä¼šåˆ›å»ºå¤šå°‘ä¸ª Tasks</span></span><br><span class="line"><span class="keyword">val</span> tasks: <span class="type">Seq</span>[<span class="type">Task</span>[_]] = <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> serializedTaskMetrics = closureSerializer.serialize(stage.latestInfo.taskMetrics).array()</span><br><span class="line">    stage <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">        stage.pendingPartitions.clear()</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">            <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">            <span class="keyword">val</span> part = partitions(id)</span><br><span class="line">            stage.pendingPartitions += id</span><br><span class="line">            <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptNumber,</span><br><span class="line">                               taskBinary, part, locs, properties, serializedTaskMetrics, <span class="type">Option</span>(jobId),</span><br><span class="line">                               <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId, stage.rdd.isBarrier())</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">            <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</span><br><span class="line">            <span class="keyword">val</span> part = partitions(p)</span><br><span class="line">            <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">            <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptNumber,</span><br><span class="line">                           taskBinary, part, locs, id, properties, serializedTaskMetrics,</span><br><span class="line">                           <span class="type">Option</span>(jobId), <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId,</span><br><span class="line">                           stage.rdd.isBarrier())</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">    abortStage(stage, <span class="string">s&quot;Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;Utils.exceptionString(e)&#125;</span>&quot;</span>, <span class="type">Some</span>(e))</span><br><span class="line">    runningStages -= stage</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// æœ€ååœ¨ taskScheduler ä¸­æäº¤ TaskSet</span></span><br><span class="line">taskScheduler.submitTasks(<span class="keyword">new</span> <span class="type">TaskSet</span>(</span><br><span class="line">    tasks.toArray, stage.id, stage.latestInfo.attemptNumber, jobId, properties,</span><br><span class="line">    stage.resourceProfileId))</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="TaskScheduler-å°†-TaskSet-é€šè¿‡-backend-çš„è°ƒåº¦åˆ†å‘åˆ°ä¸åŒçš„-executor-ä¸Šé¢"><a href="#TaskScheduler-å°†-TaskSet-é€šè¿‡-backend-çš„è°ƒåº¦åˆ†å‘åˆ°ä¸åŒçš„-executor-ä¸Šé¢" class="headerlink" title="TaskScheduler å°† TaskSet é€šè¿‡ backend çš„è°ƒåº¦åˆ†å‘åˆ°ä¸åŒçš„ executor ä¸Šé¢"></a>TaskScheduler å°† TaskSet é€šè¿‡ backend çš„è°ƒåº¦åˆ†å‘åˆ°ä¸åŒçš„ executor ä¸Šé¢</h4><p><code>TaskScheduler</code> å°† TaskSet è¿›ä¸€æ­¥åŒ…è£…æˆ TaskSetManagerã€‚ç„¶åæäº¤åˆ° <code>schedulableBuilder</code> ä¸­ã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. é€šè¿‡ TaskSet åˆ›å»º TaskSetManager å¯¹è±¡</span></span><br><span class="line"><span class="keyword">val</span> manager = createTaskSetManager(taskSet, maxTaskFailures)</span><br><span class="line"><span class="comment">// 2. å°† TaskSetManager æäº¤åˆ°ä»»åŠ¡è°ƒåº¦å™¨ SchedulerBuilder</span></span><br><span class="line">schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)</span><br><span class="line"><span class="comment">// 3. è°ƒç”¨ scheduler backend å¤„ç† Task</span></span><br><span class="line">backend.reviveOffers()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.1 LocalSchedulerBackend ä¼šå‘ localEndPoint å‘é€ä¸€ä¸ª ReviveOffers ä¿¡å·</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> localEndpoint: <span class="type">RpcEndpointRef</span> = <span class="literal">null</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">reviveOffers</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    localEndpoint.send(<span class="type">ReviveOffers</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.2 localEndPoint æ”¶åˆ°æ¶ˆæ¯åä¼šé€šè¿‡ recevie æ¥åˆ¤æ–­æ¶ˆæ¯ï¼Œå¹¶ä¸”è°ƒç”¨å¯¹åº”çš„å‡½æ•°</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">ReviveOffers</span> =&gt;</span><br><span class="line">    reviveOffers()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> <span class="type">KillTask</span>(taskId, interruptThread, reason) =&gt;</span><br><span class="line">    executor.killTask(taskId, interruptThread, reason)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reviveOffers</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// local mode doesn&#x27;t support extra resources like GPUs right now</span></span><br><span class="line">    <span class="keyword">val</span> offers = <span class="type">IndexedSeq</span>(<span class="keyword">new</span> <span class="type">WorkerOffer</span>(localExecutorId, localExecutorHostname, freeCores,</span><br><span class="line">                                            <span class="type">Some</span>(rpcEnv.address.hostPort)))</span><br><span class="line">    <span class="comment">// é¦–å…ˆé€šè¿‡ scheduler è¿›è¡Œä¸€ä¸ª Task çš„è°ƒåº¦ã€‚å°†ä»»åŠ¡æ”¾åˆ°æœ€åˆé€‚çš„ä½ç½®</span></span><br><span class="line">    <span class="keyword">for</span> (task &lt;- scheduler.resourceOffers(offers, <span class="literal">true</span>).flatten) &#123;</span><br><span class="line">        freeCores -= scheduler.<span class="type">CPUS_PER_TASK</span></span><br><span class="line">        <span class="comment">// ç„¶åå‘ executor å‘é€ä¸€ä¸ª launchTask çš„æ¶ˆæ¯</span></span><br><span class="line">        executor.launchTask(executorBackend, task)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3.2.1 scheduler ä»»åŠ¡è°ƒåº¦ï¼Œé€šè¿‡ scheduler çš„è°ƒåº¦ç®—æ³•è¿›è¡Œæ§åˆ¶</span></span><br><span class="line"><span class="keyword">val</span> sortedTaskSets = rootPool.getSortedTaskSetQueue</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> sortedSchedulableQueue = schedulableQueue.asScala.toSeq.sortWith(taskSetSchedulingAlgorithm.comparator)</span><br><span class="line"></span><br><span class="line"><span class="comment">// taskSetSchedulingAlgorithm å¯ä»¥æ˜¯ FIFO æˆ–è€… Fair</span></span><br></pre></td></tr></table></figure>

<p><code>SchedulerBuilder</code> æ˜¯ Spark çš„ä»»åŠ¡è°ƒåº¦å™¨ï¼Œæä¾›ä¸¤ç§è°ƒåº¦æ–¹å¼ï¼š</p>
<ul>
<li>FIFOSchedulableBuilder</li>
<li>FairSchedulableBuilder</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">trait</span> <span class="title">SchedulableBuilder</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">rootPool</span></span>: <span class="type">Pool</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">buildPools</span></span>(): <span class="type">Unit</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">addTaskSetManager</span></span>(manager: <span class="type">Schedulable</span>, properties: <span class="type">Properties</span>): <span class="type">Unit</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">FIFOSchedulableBuilder</span>(<span class="params">val rootPool: <span class="type">Pool</span></span>)</span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">SchedulableBuilder</span> <span class="keyword">with</span> <span class="type">Logging</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">FairSchedulableBuilder</span>(<span class="params">val rootPool: <span class="type">Pool</span>, sc: <span class="type">SparkContext</span></span>)</span></span><br><span class="line">  <span class="keyword">extends</span> <span class="type">SchedulableBuilder</span> <span class="keyword">with</span> <span class="type">Logging</span></span><br></pre></td></tr></table></figure>



<p>ä¹‹å exector ä½¿ç”¨ä¸€ä¸ª Thread æ‰§è¡Œå¯¹åº”çš„ Task</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">launchTask</span></span>(context: <span class="type">ExecutorBackend</span>, taskDescription: <span class="type">TaskDescription</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> taskId = taskDescription.taskId</span><br><span class="line">    <span class="keyword">val</span> tr = createTaskRunner(context, taskDescription)</span><br><span class="line">    runningTasks.put(taskId, tr)</span><br><span class="line">    <span class="keyword">val</span> killMark = killMarks.get(taskId)</span><br><span class="line">    <span class="keyword">if</span> (killMark != <span class="literal">null</span>) &#123;</span><br><span class="line">        tr.kill(killMark._1, killMark._2)</span><br><span class="line">        killMarks.remove(taskId)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ä»çº¿ç¨‹æ± ä¸­å–å‡ºä¸€ä¸ªçº¿ç¨‹æ‰§è¡Œ Task</span></span><br><span class="line">    threadPool.execute(tr)</span><br><span class="line">    <span class="keyword">if</span> (decommissioned) &#123;</span><br><span class="line">        log.error(<span class="string">s&quot;Launching a task while in decommissioned state.&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="shuffle-1"><a href="#shuffle-1" class="headerlink" title="shuffle"></a>shuffle</h3><p>shuffle ä¸€å®šä¼šè½ç›˜</p>
<ul>
<li>å‡å°‘è½ç›˜æ•°æ®é‡</li>
</ul>
<p><a class="link" target="_blank" rel="noopener" href="https://www.jianshu.com/p/542b243d24e9">shuffle åŸç†å’Œæ¼”è¿›<i class="fas fa-external-link-alt"></i></a></p>
<p><a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/Winner941112/article/details/82900353">é¢„èšåˆ<i class="fas fa-external-link-alt"></i></a>ï¼š</p>
<p>map-sideé¢„èšåˆä¹‹åï¼Œæ¯ä¸ªèŠ‚ç‚¹æœ¬åœ°å°±<strong>åªä¼šæœ‰ä¸€æ¡ç›¸åŒçš„key</strong>ï¼Œå› ä¸ºå¤šæ¡ç›¸åŒçš„keyéƒ½è¢«èšåˆèµ·æ¥äº†ã€‚å…¶å®ƒèŠ‚ç‚¹åœ¨æ‹‰å–æ‰€æœ‰èŠ‚ç‚¹ä¸Šçš„ç›¸åŒkeyæ—¶ï¼Œå°±ä¼šå¤§å¤§å‡å°‘éœ€è¦æ‹‰å–çš„æ•°æ®æ•°é‡ï¼Œä»è€Œä¹Ÿå°±å‡å°‘äº†ç£ç›˜IOä»¥åŠç½‘ç»œä¼ è¾“å¼€é”€ã€‚</p>
<ul>
<li>reduceByKeyå’ŒaggregateByKeyç®—å­éƒ½ä¼šä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰çš„å‡½æ•°å¯¹æ¯ä¸ªèŠ‚ç‚¹æœ¬åœ°çš„ç›¸åŒkeyè¿›è¡Œé¢„èšåˆã€‚</li>
<li>groupByKeyç®—å­æ˜¯ä¸ä¼šè¿›è¡Œé¢„èšåˆçš„ï¼Œå…¨é‡çš„æ•°æ®ä¼šåœ¨é›†ç¾¤çš„å„ä¸ªèŠ‚ç‚¹ä¹‹é—´åˆ†å‘å’Œä¼ è¾“ï¼Œæ€§èƒ½ç›¸å¯¹æ¥è¯´æ¯”è¾ƒå·®ã€‚</li>
</ul>
<h4 id="æºç éƒ¨åˆ†"><a href="#æºç éƒ¨åˆ†" class="headerlink" title="æºç éƒ¨åˆ†"></a>æºç éƒ¨åˆ†</h4><ol>
<li><p>DAGScheduler ä¸­ç”Ÿæˆ task çš„æ—¶å€™ï¼Œä¼šæ ¹æ® stage æ¥ç”Ÿæˆä¸åŒçš„ task</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">stage <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">    stage.pendingPartitions.clear()</span><br><span class="line">    partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">        <span class="comment">// ShuffleMapStage =&gt; ShuffleMapTask</span></span><br><span class="line">        <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptNumber,</span><br><span class="line">                           taskBinary, part, locs, properties, serializedTaskMetrics, <span class="type">Option</span>(jobId),</span><br><span class="line">                           <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId, stage.rdd.isBarrier())</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">    partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">        <span class="comment">// ResultStage =&gt; ResultTask</span></span><br><span class="line">        <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptNumber,</span><br><span class="line">                       taskBinary, part, locs, id, properties, serializedTaskMetrics,</span><br><span class="line">                       <span class="type">Option</span>(jobId), <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId,</span><br><span class="line">                       stage.rdd.isBarrier())</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>ã€Œmapã€ShuffleTask åœ¨ runTask çš„æœ«å°¾ä¼šè¿›è¡Œæ•°æ®çš„è½ç›˜æ“ä½œï¼Œä¸åŒçš„ shuffleWriterProcessor ä¼šäº§ç”Ÿä¸åŒçš„æ–‡ä»¶ã€‚</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dep.shuffleWriterProcessor.write(rdd, dep, mapId, context, partition)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ç„¶åé€šè¿‡ shuffleHandle é€šçŸ¥å†™æ–‡ä»¶</span></span><br><span class="line">writer = manager.getWriter[<span class="type">Any</span>, <span class="type">Any</span>](</span><br><span class="line">    dep.shuffleHandle,</span><br><span class="line">    mapId,</span><br><span class="line">    context,</span><br><span class="line">    createMetricsReporter(context))</span><br><span class="line">writer.write(</span><br><span class="line">    rdd.iterator(partition, context).asInstanceOf[<span class="type">Iterator</span>[_ &lt;: <span class="type">Product2</span>[<span class="type">Any</span>, <span class="type">Any</span>]]])</span><br></pre></td></tr></table></figure>
</li>
<li><p>ã€Œreduceã€ResultTask åœ¨ runTask ä¸­è¯»å– map äº§ç”Ÿçš„æ–‡ä»¶</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// resultMapStage çš„ runTask æ–¹æ³•</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">runTask</span></span>(context: <span class="type">TaskContext</span>): <span class="type">U</span> = &#123;</span><br><span class="line">    <span class="comment">// Deserialize the RDD and the func using the broadcast variables.</span></span><br><span class="line">    <span class="keyword">val</span> threadMXBean = <span class="type">ManagementFactory</span>.getThreadMXBean</span><br><span class="line">    <span class="keyword">val</span> deserializeStartTimeNs = <span class="type">System</span>.nanoTime()</span><br><span class="line">    <span class="keyword">val</span> deserializeStartCpuTime = <span class="keyword">if</span> (threadMXBean.isCurrentThreadCpuTimeSupported) &#123;</span><br><span class="line">        threadMXBean.getCurrentThreadCpuTime</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="number">0</span>L</span><br><span class="line">    <span class="keyword">val</span> ser = <span class="type">SparkEnv</span>.get.closureSerializer.newInstance()</span><br><span class="line">    <span class="keyword">val</span> (rdd, func) = ser.deserialize[(<span class="type">RDD</span>[<span class="type">T</span>], (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>)](</span><br><span class="line">        <span class="type">ByteBuffer</span>.wrap(taskBinary.value), <span class="type">Thread</span>.currentThread.getContextClassLoader)</span><br><span class="line">    _executorDeserializeTimeNs = <span class="type">System</span>.nanoTime() - deserializeStartTimeNs</span><br><span class="line">    _executorDeserializeCpuTime = <span class="keyword">if</span> (threadMXBean.isCurrentThreadCpuTimeSupported) &#123;</span><br><span class="line">        threadMXBean.getCurrentThreadCpuTime - deserializeStartCpuTime</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="number">0</span>L</span><br><span class="line"></span><br><span class="line">    func(context, rdd.iterator(partition, context))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// shuffleRDD iterator çš„ comput æ–¹æ³•å°±ä¼šè¯»å– map äº§ç”Ÿçš„æ–‡ä»¶</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(split: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">C</span>)] = &#123;</span><br><span class="line">    <span class="keyword">val</span> dep = dependencies.head.asInstanceOf[<span class="type">ShuffleDependency</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">C</span>]]</span><br><span class="line">    <span class="keyword">val</span> metrics = context.taskMetrics().createTempShuffleReadMetrics()</span><br><span class="line">    <span class="type">SparkEnv</span>.get.shuffleManager.getReader(</span><br><span class="line">        dep.shuffleHandle, split.index, split.index + <span class="number">1</span>, context, metrics)</span><br><span class="line">    .read()</span><br><span class="line">    .asInstanceOf[<span class="type">Iterator</span>[(<span class="type">K</span>, <span class="type">C</span>)]]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul class="copyright-info-content">
        <li>Post titleï¼šspark</li>
        <li>Post authorï¼šauggie</li>
        <li>Create timeï¼š2022-11-09 09:40:26</li>
        <li>
            Post linkï¼šhttps://ruanjiancheng.github.io/2022/11/09/spark/
        </li>
        <li>
            Copyright Noticeï¼šAll articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/tags/tech/">#tech</a>&nbsp;
                    </li>
                
            </ul>
        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2022/12/04/images/image-20220417153331430.png/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item"></span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2022/11/07/scala/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">scala</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            
<footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
                <span>2021</span> -
            
            2022
            
                &nbsp;<i class="fas fa-heart icon-animate"></i>
                &nbsp;<a href="/">auggie</a>
            
        </div>
        
            <script async 
                    src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme
            &nbsp;
            <a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.9</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-up-right-and-down-left-from-center"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85"><span class="nav-text">ç¯å¢ƒå®‰è£…</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hadoop"><span class="nav-text">hadoop</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive"><span class="nav-text">Hive</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#spark"><span class="nav-text">spark</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-%E7%8B%AC%E7%AB%8B%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%BC%96%E7%A8%8B"><span class="nav-text">Spark ç‹¬ç«‹åº”ç”¨ç¨‹åºç¼–ç¨‹</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91"><span class="nav-text">é‡åˆ°çš„å‘</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%A4%E7%A7%8D-sparkcontext-%E5%A7%BF%E5%8A%BF"><span class="nav-text">ä¸¤ç§ sparkcontext å§¿åŠ¿</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#wordCount"><span class="nav-text">wordCount</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%85%8D%E7%BD%AE-vscode-scala-spark-%E7%8E%AF%E5%A2%83"><span class="nav-text">é…ç½® vscode scala spark ç¯å¢ƒ</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#vscode-%E9%85%8D%E7%BD%AE-scalafmt-%E5%AF%84%E4%BA%86%EF%BC%8C%E5%BB%BA%E8%AE%AE%E7%94%A8-idea"><span class="nav-text">vscode é…ç½® scalafmt (å¯„äº†ï¼Œå»ºè®®ç”¨ idea)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark-%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="nav-text">Spark è¿è¡Œæµç¨‹</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RDD"><span class="nav-text">RDD</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RDD%E5%88%9B%E5%BB%BA"><span class="nav-text">RDDåˆ›å»º</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RDD%E6%93%8D%E4%BD%9C"><span class="nav-text">RDDæ“ä½œ</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#transformation"><span class="nav-text">transformation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#action"><span class="nav-text">action</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RDD%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-text">RDDæŒä¹…åŒ–</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%94%AE%E5%80%BC%E5%AF%B9-RDD"><span class="nav-text">é”®å€¼å¯¹ RDD</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F"><span class="nav-text">å…±äº«å˜é‡</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F"><span class="nav-text">å¹¿æ’­å˜é‡</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%B4%AF%E5%8A%A0%E5%99%A8"><span class="nav-text">ç´¯åŠ å™¨</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark-SQL"><span class="nav-text">Spark SQL</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#DF-%E5%88%9B%E5%BB%BA-amp-%E4%BF%9D%E5%AD%98"><span class="nav-text">DF åˆ›å»º &amp; ä¿å­˜</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%8E%B7%E5%8F%96-mysql-%E6%95%B0%E6%8D%AE"><span class="nav-text">è·å– mysql æ•°æ®</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark-Streaming"><span class="nav-text">Spark Streaming</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA%E5%99%A8-rdd%E5%A6%82%E4%BD%95%E5%AD%98%E5%82%A8"><span class="nav-text">æ•°æ®åˆ†åŒºå™¨ rddå¦‚ä½•å­˜å‚¨</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Spark-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB"><span class="nav-text">Spark æºç é˜…è¯»</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RDD-1"><span class="nav-text">RDD</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#RDD-%E5%88%86%E5%8C%BA"><span class="nav-text">RDD åˆ†åŒº</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#RDD-%E5%88%86%E5%8C%BA%E4%B8%AA%E6%95%B0%E5%88%86%E9%85%8D%E5%8E%9F%E5%88%99"><span class="nav-text">RDD åˆ†åŒºä¸ªæ•°åˆ†é…åŸåˆ™</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#RDD-%E5%88%86%E5%8C%BA%E5%86%85%E8%AE%B0%E5%BD%95%E4%B8%AA%E6%95%B0"><span class="nav-text">RDD åˆ†åŒºå†…è®°å½•ä¸ªæ•°</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RDD-%E4%BE%9D%E8%B5%96"><span class="nav-text">RDD ä¾èµ–</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#narrow"><span class="nav-text">narrow</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#shuffle"><span class="nav-text">shuffle</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RDD-%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-text">RDD æŒä¹…åŒ–</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#RDD-%E7%BC%93%E5%AD%98%E6%96%B9%E5%BC%8F"><span class="nav-text">RDD ç¼“å­˜æ–¹å¼</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#persist-cache-unpersist"><span class="nav-text">persist, cache, unpersist</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#iterator"><span class="nav-text">iterator</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#checkpoint"><span class="nav-text">checkpoint</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="nav-text">ç¯å¢ƒæ­å»º</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sparkcontext"><span class="nav-text">sparkcontext</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-text">å‰è¨€</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SparkContext%E7%BB%84%E4%BB%B6%E6%A6%82%E8%A7%88"><span class="nav-text">SparkContextç»„ä»¶æ¦‚è§ˆ</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6"><span class="nav-text">ä»»åŠ¡è°ƒåº¦</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Action-%E8%A7%A6%E5%8F%91-Job-submit-%E5%88%B0-DAGScheduler-eventProcessLoop"><span class="nav-text">Action è§¦å‘ Job submit åˆ° DAGScheduler eventProcessLoop</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DAGScheduler-%E5%AF%B9-Job-%E8%BF%9B%E8%A1%8C-Stage-%E5%88%92%E5%88%86%EF%BC%8C%E5%B9%B6%E4%B8%94%E6%8F%90%E4%BA%A4-Task-%E5%88%B0-TaskScheduler"><span class="nav-text">DAGScheduler å¯¹ Job è¿›è¡Œ Stage åˆ’åˆ†ï¼Œå¹¶ä¸”æäº¤ Task åˆ° TaskScheduler</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TaskScheduler-%E5%B0%86-TaskSet-%E9%80%9A%E8%BF%87-backend-%E7%9A%84%E8%B0%83%E5%BA%A6%E5%88%86%E5%8F%91%E5%88%B0%E4%B8%8D%E5%90%8C%E7%9A%84-executor-%E4%B8%8A%E9%9D%A2"><span class="nav-text">TaskScheduler å°† TaskSet é€šè¿‡ backend çš„è°ƒåº¦åˆ†å‘åˆ°ä¸åŒçš„ executor ä¸Šé¢</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#shuffle-1"><span class="nav-text">shuffle</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%BA%90%E7%A0%81%E9%83%A8%E5%88%86"><span class="nav-text">æºç éƒ¨åˆ†</span></a></li></ol></li></ol></li></ol>
    </div>
</div>
        </aside>
    

    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>







    
<script src="/js/code-block-tools.js"></script>





<div class="post-scripts">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>



</body>
</html>
